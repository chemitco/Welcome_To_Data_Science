{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are hyperparameters and its tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the hyperparameters for their respective models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](3.png)\n",
    "![](4.png)\n",
    "![](5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search and Random Search Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two model as random forest classifier and support vector classifier. There are three creteria for random forest classifier as criteria, n_estimators and min_samples_leaf. Also, there are three creteria for support vector classifier as kernel, c and gamma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the possible combinations for the creteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the poosile combinations can go upto 100. We have two approches to manage the combinations of hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](8.png)\n",
    "![](9.png)\n",
    "![](10.png)\n",
    "![](11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statement of the Problem- Predict whether income exceeds $50K/yr based on census data. OR To determine whether a person makes over 50K a year or not.\n",
    "\n",
    "To download the data, Please follow the link(https://archive.ics.uci.edu/ml/datasets/adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare multiple Classifiers for diffrent train and test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read dataset\n",
    "data=pd.read_csv('04+-+decisiontreeAdultIncome.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>wc</th>\n",
       "      <th>education</th>\n",
       "      <th>marital status</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours per week</th>\n",
       "      <th>IncomeClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Married</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19782</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>Married</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19783</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19784</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19785</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19786</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19787 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age        wc      education  marital status    race   gender  \\\n",
       "0       38   Private        HS-grad        Divorced   White     Male   \n",
       "1       28   Private      Bachelors         Married   Black   Female   \n",
       "2       37   Private        Masters         Married   White   Female   \n",
       "3       31   Private        Masters   Never-married   White   Female   \n",
       "4       42   Private      Bachelors         Married   White     Male   \n",
       "...    ...       ...            ...             ...     ...      ...   \n",
       "19782   53   Private        Masters         Married   White     Male   \n",
       "19783   22   Private   Some-college   Never-married   White     Male   \n",
       "19784   40   Private        HS-grad         Married   White     Male   \n",
       "19785   58   Private        HS-grad         Widowed   White   Female   \n",
       "19786   22   Private        HS-grad   Never-married   White     Male   \n",
       "\n",
       "       hours per week IncomeClass  \n",
       "0                  40       <=50K  \n",
       "1                  40       <=50K  \n",
       "2                  40       <=50K  \n",
       "3                  50        >50K  \n",
       "4                  40        >50K  \n",
       "...               ...         ...  \n",
       "19782              40        >50K  \n",
       "19783              40       <=50K  \n",
       "19784              40        >50K  \n",
       "19785              40       <=50K  \n",
       "19786              20       <=50K  \n",
       "\n",
       "[19787 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description about the data set and features\n",
    "\n",
    "age: continuous.\n",
    "\n",
    "workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "\n",
    "fnlwgt: continuous.\n",
    "\n",
    "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "\n",
    "education-num: continuous.\n",
    "\n",
    "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "\n",
    "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "\n",
    "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "\n",
    "sex: Female, Male.\n",
    "\n",
    "capital-gain: continuous.\n",
    "\n",
    "capital-loss: continuous.\n",
    "\n",
    "hours-per-week: continuous.\n",
    "\n",
    "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy variables\n",
    "data_prep=pd.get_dummies(data,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the X and Y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_prep.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data_prep.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Decision Tree classifier from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc= DecisionTreeClassifier(random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random forest classifier from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc= RandomForestClassifier(random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and train Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and train Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc= LogisticRegression(random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_param={'n_estimators':[10,15,20],\n",
    "          'min_samples_split':[8,16],\n",
    "          'min_samples_leaf':[1,2,3,4,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different possibles combinations of parameter\n",
    "#(3*2*5=30)---> models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the grid search objects\n",
    "rfc_grid = GridSearchCV(estimator=rfc, \n",
    "                        param_grid=rfc_param,\n",
    "                        scoring='accuracy',\n",
    "                        cv=10,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of jobs=Models*fold=30*10=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 15, 20],\n",
       " 'min_samples_split': [8, 16],\n",
       " 'min_samples_leaf': [1, 2, 3, 4, 5]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=1234),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'min_samples_leaf': [1, 2, 3, 4, 5],\n",
       "                         'min_samples_split': [8, 16],\n",
       "                         'n_estimators': [10, 15, 20]},\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the data to grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_grid_fit=rfc_grid.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the result of gridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result_rfc=rfc_grid_fit.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.45668049, 0.66292915, 0.81433065, 0.45361254, 0.60140274,\n",
       "        0.82010536, 0.39444685, 0.57964857, 0.66115172, 0.44950752,\n",
       "        0.86538608, 0.79417508, 0.38945613, 0.49168406, 0.64916961,\n",
       "        0.37311504, 0.51233435, 0.68502252, 0.34607711, 0.53447428,\n",
       "        0.67422717, 0.34477339, 0.48221769, 0.68746185, 0.47283773,\n",
       "        0.72615461, 0.91873999, 0.42735655, 0.6708653 , 0.77842727]),\n",
       " 'std_fit_time': array([0.11297166, 0.15059306, 0.09597708, 0.04941699, 0.05503439,\n",
       "        0.08481615, 0.05022412, 0.04823105, 0.0960839 , 0.13203082,\n",
       "        0.23014196, 0.14076624, 0.06592218, 0.07724044, 0.08649928,\n",
       "        0.0666882 , 0.07205434, 0.09178141, 0.05774798, 0.07067668,\n",
       "        0.09762898, 0.05930529, 0.0712308 , 0.20757168, 0.14407306,\n",
       "        0.17313657, 0.14960031, 0.05085416, 0.14994126, 0.14702281]),\n",
       " 'mean_score_time': array([0.01994457, 0.03131347, 0.04906604, 0.02234087, 0.0290211 ,\n",
       "        0.03819802, 0.0256314 , 0.02533505, 0.03425844, 0.02842512,\n",
       "        0.04767184, 0.03820243, 0.01974602, 0.02323782, 0.02871995,\n",
       "        0.0213491 , 0.02423475, 0.04069264, 0.01724999, 0.02213829,\n",
       "        0.0330076 , 0.01635542, 0.02483401, 0.0432843 , 0.02663076,\n",
       "        0.03540444, 0.04198842, 0.03062236, 0.03650258, 0.02892225]),\n",
       " 'std_score_time': array([0.00583392, 0.009652  , 0.01613903, 0.00722157, 0.00830288,\n",
       "        0.01029839, 0.00793733, 0.00441959, 0.01157891, 0.01359405,\n",
       "        0.02399362, 0.0127475 , 0.00652221, 0.00490722, 0.00751597,\n",
       "        0.00791497, 0.00647899, 0.01130773, 0.0050291 , 0.00480601,\n",
       "        0.01114229, 0.00127759, 0.00779575, 0.02353866, 0.01271567,\n",
       "        0.01504149, 0.01460585, 0.01752109, 0.01369085, 0.00751497]),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "                    4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[8, 8, 8, 16, 16, 16, 8, 8, 8, 16, 16, 16, 8, 8, 8, 16,\n",
       "                    16, 16, 8, 8, 8, 16, 16, 16, 8, 8, 8, 16, 16, 16],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 15, 20, 10, 15, 20, 10, 15, 20, 10, 15, 20, 10, 15,\n",
       "                    20, 10, 15, 20, 10, 15, 20, 10, 15, 20, 10, 15, 20, 10,\n",
       "                    15, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'min_samples_leaf': 1,\n",
       "   'min_samples_split': 8,\n",
       "   'n_estimators': 10},\n",
       "  {'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 15},\n",
       "  {'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 20},\n",
       "  {'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 10},\n",
       "  {'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 15},\n",
       "  {'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 20},\n",
       "  {'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 10},\n",
       "  {'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 15},\n",
       "  {'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 20},\n",
       "  {'min_samples_leaf': 2, 'min_samples_split': 16, 'n_estimators': 10},\n",
       "  {'min_samples_leaf': 2, 'min_samples_split': 16, 'n_estimators': 15},\n",
       "  {'min_samples_leaf': 2, 'min_samples_split': 16, 'n_estimators': 20},\n",
       "  {'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 10},\n",
       "  {'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 15},\n",
       "  {'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 20},\n",
       "  {'min_samples_leaf': 3, 'min_samples_split': 16, 'n_estimators': 10},\n",
       "  {'min_samples_leaf': 3, 'min_samples_split': 16, 'n_estimators': 15},\n",
       "  {'min_samples_leaf': 3, 'min_samples_split': 16, 'n_estimators': 20},\n",
       "  {'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 10},\n",
       "  {'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 15},\n",
       "  {'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 20},\n",
       "  {'min_samples_leaf': 4, 'min_samples_split': 16, 'n_estimators': 10},\n",
       "  {'min_samples_leaf': 4, 'min_samples_split': 16, 'n_estimators': 15},\n",
       "  {'min_samples_leaf': 4, 'min_samples_split': 16, 'n_estimators': 20},\n",
       "  {'min_samples_leaf': 5, 'min_samples_split': 8, 'n_estimators': 10},\n",
       "  {'min_samples_leaf': 5, 'min_samples_split': 8, 'n_estimators': 15},\n",
       "  {'min_samples_leaf': 5, 'min_samples_split': 8, 'n_estimators': 20},\n",
       "  {'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 10},\n",
       "  {'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 15},\n",
       "  {'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 20}],\n",
       " 'split0_test_score': array([0.79080344, 0.79737241, 0.79888833, 0.80192016, 0.80343608,\n",
       "        0.80090955, 0.8054573 , 0.79989894, 0.804952  , 0.81303689,\n",
       "        0.8145528 , 0.81505811, 0.8145528 , 0.80798383, 0.81859525,\n",
       "        0.81051036, 0.80899444, 0.81202628, 0.81354219, 0.81505811,\n",
       "        0.81152097, 0.81758464, 0.81859525, 0.82061647, 0.81758464,\n",
       "        0.82112178, 0.81707933, 0.81707933, 0.81910056, 0.81556342]),\n",
       " 'split1_test_score': array([0.79231935, 0.7963618 , 0.79181405, 0.79989894, 0.79888833,\n",
       "        0.80141486, 0.79838302, 0.80090955, 0.80394138, 0.79939363,\n",
       "        0.804952  , 0.80646791, 0.80192016, 0.80596261, 0.8054573 ,\n",
       "        0.80293077, 0.80646791, 0.80747852, 0.80242547, 0.80596261,\n",
       "        0.80646791, 0.80293077, 0.80394138, 0.80798383, 0.79939363,\n",
       "        0.80040424, 0.80141486, 0.80596261, 0.80697322, 0.804952  ]),\n",
       " 'split2_test_score': array([0.81202628, 0.81960586, 0.81960586, 0.81910056, 0.82011117,\n",
       "        0.82112178, 0.81859525, 0.82112178, 0.8226377 , 0.8226377 ,\n",
       "        0.82162708, 0.82061647, 0.8226377 , 0.82668014, 0.82415361,\n",
       "        0.82718545, 0.82516422, 0.82364831, 0.8226377 , 0.8226377 ,\n",
       "        0.8226377 , 0.82112178, 0.82061647, 0.82061647, 0.81758464,\n",
       "        0.81556342, 0.81606872, 0.82465892, 0.82415361, 0.823143  ]),\n",
       " 'split3_test_score': array([0.7877716 , 0.79029813, 0.79585649, 0.79181405, 0.79029813,\n",
       "        0.79332996, 0.79383527, 0.7963618 , 0.79737241, 0.80040424,\n",
       "        0.80242547, 0.8054573 , 0.80899444, 0.80848914, 0.80646791,\n",
       "        0.8054573 , 0.80293077, 0.80444669, 0.80646791, 0.80596261,\n",
       "        0.8054573 , 0.80697322, 0.80596261, 0.80747852, 0.80343608,\n",
       "        0.80899444, 0.80848914, 0.80747852, 0.8054573 , 0.804952  ]),\n",
       " 'split4_test_score': array([0.81202628, 0.80949975, 0.81101566, 0.81808994, 0.81707933,\n",
       "        0.8145528 , 0.82566953, 0.823143  , 0.81910056, 0.8226377 ,\n",
       "        0.81960586, 0.82162708, 0.82566953, 0.823143  , 0.82566953,\n",
       "        0.82364831, 0.82516422, 0.82112178, 0.823143  , 0.82415361,\n",
       "        0.82415361, 0.82668014, 0.82516422, 0.82162708, 0.82415361,\n",
       "        0.82566953, 0.82566953, 0.82769075, 0.81910056, 0.81910056]),\n",
       " 'split5_test_score': array([0.80697322, 0.81303689, 0.80444669, 0.81152097, 0.81152097,\n",
       "        0.81808994, 0.8226377 , 0.82617484, 0.81859525, 0.8145528 ,\n",
       "        0.81859525, 0.82819606, 0.8140475 , 0.8226377 , 0.8226377 ,\n",
       "        0.81859525, 0.81556342, 0.82112178, 0.82061647, 0.81960586,\n",
       "        0.82566953, 0.81707933, 0.81707933, 0.81960586, 0.81859525,\n",
       "        0.82364831, 0.82566953, 0.82011117, 0.82213239, 0.82011117]),\n",
       " 'split6_test_score': array([0.81000505, 0.81202628, 0.81253158, 0.81202628, 0.80798383,\n",
       "        0.81051036, 0.81000505, 0.8145528 , 0.81859525, 0.82061647,\n",
       "        0.81707933, 0.81758464, 0.81354219, 0.81758464, 0.81758464,\n",
       "        0.81303689, 0.81606872, 0.81152097, 0.8140475 , 0.81101566,\n",
       "        0.81051036, 0.81556342, 0.81354219, 0.81354219, 0.81556342,\n",
       "        0.8226377 , 0.81707933, 0.81808994, 0.81859525, 0.81505811]),\n",
       " 'split7_test_score': array([0.81648129, 0.82103134, 0.81951466, 0.82305359, 0.82355915,\n",
       "        0.82659252, 0.82861476, 0.82355915, 0.82760364, 0.82355915,\n",
       "        0.82962588, 0.83013145, 0.82608696, 0.82861476, 0.8255814 ,\n",
       "        0.81799798, 0.82608696, 0.82507583, 0.83013145, 0.8281092 ,\n",
       "        0.82962588, 0.82608696, 0.82760364, 0.82760364, 0.82153691,\n",
       "        0.8255814 , 0.82305359, 0.8281092 , 0.82962588, 0.8281092 ]),\n",
       " 'split8_test_score': array([0.79575329, 0.80283114, 0.80283114, 0.80637007, 0.80940344,\n",
       "        0.80839232, 0.809909  , 0.81648129, 0.81698686, 0.81193124,\n",
       "        0.81547017, 0.81749242, 0.81294237, 0.81294237, 0.81648129,\n",
       "        0.81698686, 0.81395349, 0.81648129, 0.81193124, 0.81698686,\n",
       "        0.81951466, 0.81496461, 0.81698686, 0.82002022, 0.82002022,\n",
       "        0.81850354, 0.8190091 , 0.81698686, 0.81951466, 0.81850354]),\n",
       " 'split9_test_score': array([0.80687563, 0.81597573, 0.81344793, 0.809909  , 0.80738119,\n",
       "        0.81142568, 0.809909  , 0.80637007, 0.81041456, 0.81496461,\n",
       "        0.8190091 , 0.81445905, 0.82103134, 0.81648129, 0.81749242,\n",
       "        0.81749242, 0.81951466, 0.82052578, 0.81597573, 0.81597573,\n",
       "        0.82052578, 0.81547017, 0.81294237, 0.81496461, 0.8124368 ,\n",
       "        0.81547017, 0.81294237, 0.81749242, 0.81799798, 0.82103134]),\n",
       " 'mean_test_score': array([0.80310354, 0.80780393, 0.80699524, 0.80937036, 0.80896616,\n",
       "        0.81063398, 0.81230159, 0.81285732, 0.81401996, 0.81437344,\n",
       "        0.8162943 , 0.81770905, 0.8161425 , 0.81705195, 0.8180121 ,\n",
       "        0.81538416, 0.81599088, 0.81634472, 0.81609187, 0.81654679,\n",
       "        0.81760837, 0.8164455 , 0.81624343, 0.81740589, 0.81503052,\n",
       "        0.81775945, 0.81664755, 0.81836597, 0.81826514, 0.81705243]),\n",
       " 'std_test_score': array([0.00985756, 0.01000018, 0.00921039, 0.0091233 , 0.00945423,\n",
       "        0.00959307, 0.01090672, 0.01052067, 0.0089956 , 0.00829225,\n",
       "        0.00745065, 0.00763032, 0.00730091, 0.00768587, 0.00684888,\n",
       "        0.00717367, 0.00772782, 0.00674393, 0.0078584 , 0.00703839,\n",
       "        0.0080553 , 0.00705384, 0.00713982, 0.00601929, 0.0074978 ,\n",
       "        0.00763007, 0.00722798, 0.00708029, 0.00688028, 0.00699908]),\n",
       " 'rank_test_score': array([30, 28, 29, 26, 27, 25, 24, 23, 22, 21, 14,  5, 16,  9,  3, 19, 18,\n",
       "        13, 17, 11,  6, 12, 15,  7, 20,  4, 10,  1,  2,  8]),\n",
       " 'split0_train_score': array([0.87146226, 0.87230458, 0.87365229, 0.85601977, 0.85877134,\n",
       "        0.85899596, 0.85882749, 0.86011905, 0.8607929 , 0.84798967,\n",
       "        0.8484389 , 0.85017969, 0.84737197, 0.84956199, 0.85017969,\n",
       "        0.84310422, 0.84467655, 0.8453504 , 0.84394654, 0.84624888,\n",
       "        0.84731581, 0.84035265, 0.84074573, 0.8415319 , 0.83956649,\n",
       "        0.83928571, 0.8402965 , 0.83878032, 0.83945418, 0.83951033]),\n",
       " 'split1_train_score': array([0.87185535, 0.87410153, 0.87573001, 0.85820979, 0.86107367,\n",
       "        0.86230907, 0.85905211, 0.86073675, 0.86152291, 0.85023585,\n",
       "        0.85107817, 0.85169587, 0.84838275, 0.85135894, 0.8509097 ,\n",
       "        0.84417116, 0.84613657, 0.8464735 , 0.84428347, 0.84641734,\n",
       "        0.84703504, 0.84360961, 0.84383423, 0.84428347, 0.84007188,\n",
       "        0.84175651, 0.84186882, 0.84080189, 0.84136343, 0.84080189]),\n",
       " 'split2_train_score': array([0.86983378, 0.87224843, 0.87264151, 0.85635669, 0.85714286,\n",
       "        0.85927673, 0.85753594, 0.8583221 , 0.85871518, 0.84832659,\n",
       "        0.84821429, 0.84787736, 0.85046047, 0.85068509, 0.8509097 ,\n",
       "        0.84433962, 0.8446204 , 0.84445193, 0.8434973 , 0.84372192,\n",
       "        0.8446204 , 0.83979111, 0.83894879, 0.84057727, 0.83866801,\n",
       "        0.8396788 , 0.83962264, 0.8384434 , 0.83962264, 0.84040881]),\n",
       " 'split3_train_score': array([0.87264151, 0.87359614, 0.87544924, 0.85961366, 0.85989443,\n",
       "        0.86096137, 0.86039982, 0.86096137, 0.86062444, 0.84944969,\n",
       "        0.85158356, 0.85158356, 0.85119048, 0.85186433, 0.85265049,\n",
       "        0.84501348, 0.84742812, 0.84686658, 0.84574349, 0.84630503,\n",
       "        0.8478212 , 0.8421496 , 0.84175651, 0.84220575, 0.84052111,\n",
       "        0.84316038, 0.84372192, 0.83883648, 0.84085804, 0.84119497]),\n",
       " 'split4_train_score': array([0.87084456, 0.87382075, 0.87477538, 0.85697439, 0.85882749,\n",
       "        0.8595575 , 0.85747978, 0.8583221 , 0.86034367, 0.84883199,\n",
       "        0.84978661, 0.85096586, 0.85051662, 0.85135894, 0.85130279,\n",
       "        0.8434973 , 0.84467655, 0.8458558 , 0.8428796 , 0.84366577,\n",
       "        0.84546271, 0.83928571, 0.8409142 , 0.84158805, 0.83838724,\n",
       "        0.84040881, 0.8410265 , 0.83805031, 0.83821878, 0.83894879]),\n",
       " 'split5_train_score': array([0.87022686, 0.87179919, 0.87382075, 0.8570867 , 0.85764825,\n",
       "        0.85798518, 0.85534591, 0.85792902, 0.8583221 , 0.84776505,\n",
       "        0.84900045, 0.85046047, 0.84770889, 0.84978661, 0.85068509,\n",
       "        0.84332884, 0.84501348, 0.84501348, 0.84293576, 0.84529425,\n",
       "        0.84608041, 0.83911725, 0.8410265 , 0.84113881, 0.83861186,\n",
       "        0.83883648, 0.8390611 , 0.83771339, 0.83866801, 0.84035265]),\n",
       " 'split6_train_score': array([0.87078841, 0.87213612, 0.87331536, 0.85686208, 0.85843441,\n",
       "        0.85877134, 0.8570867 , 0.85865903, 0.85916442, 0.84742812,\n",
       "        0.84810198, 0.84855121, 0.84652965, 0.84933738, 0.84973046,\n",
       "        0.84467655, 0.8465858 , 0.84669811, 0.84478886, 0.84501348,\n",
       "        0.84568733, 0.83833109, 0.83956649, 0.84074573, 0.83855571,\n",
       "        0.84130728, 0.84119497, 0.83805031, 0.83878032, 0.84001572]),\n",
       " 'split7_train_score': array([0.87045876, 0.87130103, 0.87231175, 0.85720703, 0.8580493 ,\n",
       "        0.85827391, 0.85529788, 0.85664552, 0.85737548, 0.84816666,\n",
       "        0.84928968, 0.84884047, 0.84968274, 0.85091808, 0.85091808,\n",
       "        0.8437307 , 0.84490988, 0.84558369, 0.84075467, 0.84243922,\n",
       "        0.84170925, 0.84137234, 0.8417654 , 0.84271997, 0.83951934,\n",
       "        0.83940704, 0.84041777, 0.8377225 , 0.83789095, 0.83862092]),\n",
       " 'split8_train_score': array([0.87191869, 0.87371554, 0.87427705, 0.85872312, 0.85922848,\n",
       "        0.85973384, 0.85821776, 0.85894772, 0.85962154, 0.84889663,\n",
       "        0.85013196, 0.85136729, 0.84766129, 0.84912123, 0.84895278,\n",
       "        0.84485373, 0.84485373, 0.84648212, 0.84429221, 0.84738054,\n",
       "        0.845696  , 0.84086698, 0.84243922, 0.84300073, 0.83856477,\n",
       "        0.84086698, 0.84053007, 0.83721714, 0.83940704, 0.84019316]),\n",
       " 'split9_train_score': array([0.86916727, 0.87248021, 0.87371554, 0.85687012, 0.85855466,\n",
       "        0.8601269 , 0.85715088, 0.85771239, 0.85861081, 0.84878432,\n",
       "        0.84951429, 0.84962659, 0.84940199, 0.8518165 , 0.85187265,\n",
       "        0.84474142, 0.84648212, 0.84636981, 0.84305688, 0.84294458,\n",
       "        0.84457297, 0.83974395, 0.84030546, 0.84114773, 0.83648717,\n",
       "        0.83890168, 0.83929474, 0.83895783, 0.84002471, 0.83940704]),\n",
       " 'mean_train_score': array([0.87091975, 0.87275035, 0.87396889, 0.85739234, 0.85876249,\n",
       "        0.85959918, 0.85763943, 0.8588355 , 0.85950935, 0.84858746,\n",
       "        0.84951399, 0.85011484, 0.84889069, 0.85058091, 0.85081114,\n",
       "        0.8441457 , 0.84553832, 0.84591454, 0.84361788, 0.8449431 ,\n",
       "        0.84560011, 0.84046203, 0.84113025, 0.84189394, 0.83889536,\n",
       "        0.84036097, 0.8407035 , 0.83845736, 0.83942881, 0.83994543]),\n",
       " 'std_train_score': array([0.00100489, 0.00092328, 0.0010564 , 0.00105765, 0.00106623,\n",
       "        0.00122523, 0.00150615, 0.00131269, 0.00123183, 0.00079232,\n",
       "        0.0011108 , 0.00128011, 0.00149441, 0.00099273, 0.00099089,\n",
       "        0.00065375, 0.00096872, 0.00075793, 0.0012819 , 0.00158711,\n",
       "        0.00165396, 0.00149862, 0.00133829, 0.00110082, 0.00106214,\n",
       "        0.00133877, 0.00130163, 0.0009465 , 0.00104918, 0.00077256])}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covert the results in data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result_rfc=pd.DataFrame.from_dict(rfc_grid_fit.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.456680</td>\n",
       "      <td>0.112972</td>\n",
       "      <td>0.019945</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 8...</td>\n",
       "      <td>0.790803</td>\n",
       "      <td>0.792319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869834</td>\n",
       "      <td>0.872642</td>\n",
       "      <td>0.870845</td>\n",
       "      <td>0.870227</td>\n",
       "      <td>0.870788</td>\n",
       "      <td>0.870459</td>\n",
       "      <td>0.871919</td>\n",
       "      <td>0.869167</td>\n",
       "      <td>0.870920</td>\n",
       "      <td>0.001005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.662929</td>\n",
       "      <td>0.150593</td>\n",
       "      <td>0.031313</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 8...</td>\n",
       "      <td>0.797372</td>\n",
       "      <td>0.796362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872248</td>\n",
       "      <td>0.873596</td>\n",
       "      <td>0.873821</td>\n",
       "      <td>0.871799</td>\n",
       "      <td>0.872136</td>\n",
       "      <td>0.871301</td>\n",
       "      <td>0.873716</td>\n",
       "      <td>0.872480</td>\n",
       "      <td>0.872750</td>\n",
       "      <td>0.000923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.814331</td>\n",
       "      <td>0.095977</td>\n",
       "      <td>0.049066</td>\n",
       "      <td>0.016139</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 8...</td>\n",
       "      <td>0.798888</td>\n",
       "      <td>0.791814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872642</td>\n",
       "      <td>0.875449</td>\n",
       "      <td>0.874775</td>\n",
       "      <td>0.873821</td>\n",
       "      <td>0.873315</td>\n",
       "      <td>0.872312</td>\n",
       "      <td>0.874277</td>\n",
       "      <td>0.873716</td>\n",
       "      <td>0.873969</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.453613</td>\n",
       "      <td>0.049417</td>\n",
       "      <td>0.022341</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 1...</td>\n",
       "      <td>0.801920</td>\n",
       "      <td>0.799899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856357</td>\n",
       "      <td>0.859614</td>\n",
       "      <td>0.856974</td>\n",
       "      <td>0.857087</td>\n",
       "      <td>0.856862</td>\n",
       "      <td>0.857207</td>\n",
       "      <td>0.858723</td>\n",
       "      <td>0.856870</td>\n",
       "      <td>0.857392</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.601403</td>\n",
       "      <td>0.055034</td>\n",
       "      <td>0.029021</td>\n",
       "      <td>0.008303</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 1...</td>\n",
       "      <td>0.803436</td>\n",
       "      <td>0.798888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.859894</td>\n",
       "      <td>0.858827</td>\n",
       "      <td>0.857648</td>\n",
       "      <td>0.858434</td>\n",
       "      <td>0.858049</td>\n",
       "      <td>0.859228</td>\n",
       "      <td>0.858555</td>\n",
       "      <td>0.858762</td>\n",
       "      <td>0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.820105</td>\n",
       "      <td>0.084816</td>\n",
       "      <td>0.038198</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>{'min_samples_leaf': 1, 'min_samples_split': 1...</td>\n",
       "      <td>0.800910</td>\n",
       "      <td>0.801415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859277</td>\n",
       "      <td>0.860961</td>\n",
       "      <td>0.859558</td>\n",
       "      <td>0.857985</td>\n",
       "      <td>0.858771</td>\n",
       "      <td>0.858274</td>\n",
       "      <td>0.859734</td>\n",
       "      <td>0.860127</td>\n",
       "      <td>0.859599</td>\n",
       "      <td>0.001225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.394447</td>\n",
       "      <td>0.050224</td>\n",
       "      <td>0.025631</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>{'min_samples_leaf': 2, 'min_samples_split': 8...</td>\n",
       "      <td>0.805457</td>\n",
       "      <td>0.798383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857536</td>\n",
       "      <td>0.860400</td>\n",
       "      <td>0.857480</td>\n",
       "      <td>0.855346</td>\n",
       "      <td>0.857087</td>\n",
       "      <td>0.855298</td>\n",
       "      <td>0.858218</td>\n",
       "      <td>0.857151</td>\n",
       "      <td>0.857639</td>\n",
       "      <td>0.001506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.579649</td>\n",
       "      <td>0.048231</td>\n",
       "      <td>0.025335</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_leaf': 2, 'min_samples_split': 8...</td>\n",
       "      <td>0.799899</td>\n",
       "      <td>0.800910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858322</td>\n",
       "      <td>0.860961</td>\n",
       "      <td>0.858322</td>\n",
       "      <td>0.857929</td>\n",
       "      <td>0.858659</td>\n",
       "      <td>0.856646</td>\n",
       "      <td>0.858948</td>\n",
       "      <td>0.857712</td>\n",
       "      <td>0.858836</td>\n",
       "      <td>0.001313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.661152</td>\n",
       "      <td>0.096084</td>\n",
       "      <td>0.034258</td>\n",
       "      <td>0.011579</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>{'min_samples_leaf': 2, 'min_samples_split': 8...</td>\n",
       "      <td>0.804952</td>\n",
       "      <td>0.803941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858715</td>\n",
       "      <td>0.860624</td>\n",
       "      <td>0.860344</td>\n",
       "      <td>0.858322</td>\n",
       "      <td>0.859164</td>\n",
       "      <td>0.857375</td>\n",
       "      <td>0.859622</td>\n",
       "      <td>0.858611</td>\n",
       "      <td>0.859509</td>\n",
       "      <td>0.001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.449508</td>\n",
       "      <td>0.132031</td>\n",
       "      <td>0.028425</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>{'min_samples_leaf': 2, 'min_samples_split': 1...</td>\n",
       "      <td>0.813037</td>\n",
       "      <td>0.799394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848327</td>\n",
       "      <td>0.849450</td>\n",
       "      <td>0.848832</td>\n",
       "      <td>0.847765</td>\n",
       "      <td>0.847428</td>\n",
       "      <td>0.848167</td>\n",
       "      <td>0.848897</td>\n",
       "      <td>0.848784</td>\n",
       "      <td>0.848587</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.865386</td>\n",
       "      <td>0.230142</td>\n",
       "      <td>0.047672</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_leaf': 2, 'min_samples_split': 1...</td>\n",
       "      <td>0.814553</td>\n",
       "      <td>0.804952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.851584</td>\n",
       "      <td>0.849787</td>\n",
       "      <td>0.849000</td>\n",
       "      <td>0.848102</td>\n",
       "      <td>0.849290</td>\n",
       "      <td>0.850132</td>\n",
       "      <td>0.849514</td>\n",
       "      <td>0.849514</td>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.794175</td>\n",
       "      <td>0.140766</td>\n",
       "      <td>0.038202</td>\n",
       "      <td>0.012747</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>{'min_samples_leaf': 2, 'min_samples_split': 1...</td>\n",
       "      <td>0.815058</td>\n",
       "      <td>0.806468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847877</td>\n",
       "      <td>0.851584</td>\n",
       "      <td>0.850966</td>\n",
       "      <td>0.850460</td>\n",
       "      <td>0.848551</td>\n",
       "      <td>0.848840</td>\n",
       "      <td>0.851367</td>\n",
       "      <td>0.849627</td>\n",
       "      <td>0.850115</td>\n",
       "      <td>0.001280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.389456</td>\n",
       "      <td>0.065922</td>\n",
       "      <td>0.019746</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>{'min_samples_leaf': 3, 'min_samples_split': 8...</td>\n",
       "      <td>0.814553</td>\n",
       "      <td>0.801920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850460</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.850517</td>\n",
       "      <td>0.847709</td>\n",
       "      <td>0.846530</td>\n",
       "      <td>0.849683</td>\n",
       "      <td>0.847661</td>\n",
       "      <td>0.849402</td>\n",
       "      <td>0.848891</td>\n",
       "      <td>0.001494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.491684</td>\n",
       "      <td>0.077240</td>\n",
       "      <td>0.023238</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_leaf': 3, 'min_samples_split': 8...</td>\n",
       "      <td>0.807984</td>\n",
       "      <td>0.805963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850685</td>\n",
       "      <td>0.851864</td>\n",
       "      <td>0.851359</td>\n",
       "      <td>0.849787</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>0.850918</td>\n",
       "      <td>0.849121</td>\n",
       "      <td>0.851816</td>\n",
       "      <td>0.850581</td>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.649170</td>\n",
       "      <td>0.086499</td>\n",
       "      <td>0.028720</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>{'min_samples_leaf': 3, 'min_samples_split': 8...</td>\n",
       "      <td>0.818595</td>\n",
       "      <td>0.805457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850910</td>\n",
       "      <td>0.852650</td>\n",
       "      <td>0.851303</td>\n",
       "      <td>0.850685</td>\n",
       "      <td>0.849730</td>\n",
       "      <td>0.850918</td>\n",
       "      <td>0.848953</td>\n",
       "      <td>0.851873</td>\n",
       "      <td>0.850811</td>\n",
       "      <td>0.000991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.373115</td>\n",
       "      <td>0.066688</td>\n",
       "      <td>0.021349</td>\n",
       "      <td>0.007915</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>{'min_samples_leaf': 3, 'min_samples_split': 1...</td>\n",
       "      <td>0.810510</td>\n",
       "      <td>0.802931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844340</td>\n",
       "      <td>0.845013</td>\n",
       "      <td>0.843497</td>\n",
       "      <td>0.843329</td>\n",
       "      <td>0.844677</td>\n",
       "      <td>0.843731</td>\n",
       "      <td>0.844854</td>\n",
       "      <td>0.844741</td>\n",
       "      <td>0.844146</td>\n",
       "      <td>0.000654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.512334</td>\n",
       "      <td>0.072054</td>\n",
       "      <td>0.024235</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_leaf': 3, 'min_samples_split': 1...</td>\n",
       "      <td>0.808994</td>\n",
       "      <td>0.806468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844620</td>\n",
       "      <td>0.847428</td>\n",
       "      <td>0.844677</td>\n",
       "      <td>0.845013</td>\n",
       "      <td>0.846586</td>\n",
       "      <td>0.844910</td>\n",
       "      <td>0.844854</td>\n",
       "      <td>0.846482</td>\n",
       "      <td>0.845538</td>\n",
       "      <td>0.000969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.685023</td>\n",
       "      <td>0.091781</td>\n",
       "      <td>0.040693</td>\n",
       "      <td>0.011308</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>{'min_samples_leaf': 3, 'min_samples_split': 1...</td>\n",
       "      <td>0.812026</td>\n",
       "      <td>0.807479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844452</td>\n",
       "      <td>0.846867</td>\n",
       "      <td>0.845856</td>\n",
       "      <td>0.845013</td>\n",
       "      <td>0.846698</td>\n",
       "      <td>0.845584</td>\n",
       "      <td>0.846482</td>\n",
       "      <td>0.846370</td>\n",
       "      <td>0.845915</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.346077</td>\n",
       "      <td>0.057748</td>\n",
       "      <td>0.017250</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>{'min_samples_leaf': 4, 'min_samples_split': 8...</td>\n",
       "      <td>0.813542</td>\n",
       "      <td>0.802425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843497</td>\n",
       "      <td>0.845743</td>\n",
       "      <td>0.842880</td>\n",
       "      <td>0.842936</td>\n",
       "      <td>0.844789</td>\n",
       "      <td>0.840755</td>\n",
       "      <td>0.844292</td>\n",
       "      <td>0.843057</td>\n",
       "      <td>0.843618</td>\n",
       "      <td>0.001282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.534474</td>\n",
       "      <td>0.070677</td>\n",
       "      <td>0.022138</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_leaf': 4, 'min_samples_split': 8...</td>\n",
       "      <td>0.815058</td>\n",
       "      <td>0.805963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843722</td>\n",
       "      <td>0.846305</td>\n",
       "      <td>0.843666</td>\n",
       "      <td>0.845294</td>\n",
       "      <td>0.845013</td>\n",
       "      <td>0.842439</td>\n",
       "      <td>0.847381</td>\n",
       "      <td>0.842945</td>\n",
       "      <td>0.844943</td>\n",
       "      <td>0.001587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.674227</td>\n",
       "      <td>0.097629</td>\n",
       "      <td>0.033008</td>\n",
       "      <td>0.011142</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>{'min_samples_leaf': 4, 'min_samples_split': 8...</td>\n",
       "      <td>0.811521</td>\n",
       "      <td>0.806468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844620</td>\n",
       "      <td>0.847821</td>\n",
       "      <td>0.845463</td>\n",
       "      <td>0.846080</td>\n",
       "      <td>0.845687</td>\n",
       "      <td>0.841709</td>\n",
       "      <td>0.845696</td>\n",
       "      <td>0.844573</td>\n",
       "      <td>0.845600</td>\n",
       "      <td>0.001654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.344773</td>\n",
       "      <td>0.059305</td>\n",
       "      <td>0.016355</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>{'min_samples_leaf': 4, 'min_samples_split': 1...</td>\n",
       "      <td>0.817585</td>\n",
       "      <td>0.802931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839791</td>\n",
       "      <td>0.842150</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.839117</td>\n",
       "      <td>0.838331</td>\n",
       "      <td>0.841372</td>\n",
       "      <td>0.840867</td>\n",
       "      <td>0.839744</td>\n",
       "      <td>0.840462</td>\n",
       "      <td>0.001499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.482218</td>\n",
       "      <td>0.071231</td>\n",
       "      <td>0.024834</td>\n",
       "      <td>0.007796</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_leaf': 4, 'min_samples_split': 1...</td>\n",
       "      <td>0.818595</td>\n",
       "      <td>0.803941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838949</td>\n",
       "      <td>0.841757</td>\n",
       "      <td>0.840914</td>\n",
       "      <td>0.841027</td>\n",
       "      <td>0.839566</td>\n",
       "      <td>0.841765</td>\n",
       "      <td>0.842439</td>\n",
       "      <td>0.840305</td>\n",
       "      <td>0.841130</td>\n",
       "      <td>0.001338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.687462</td>\n",
       "      <td>0.207572</td>\n",
       "      <td>0.043284</td>\n",
       "      <td>0.023539</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>{'min_samples_leaf': 4, 'min_samples_split': 1...</td>\n",
       "      <td>0.820616</td>\n",
       "      <td>0.807984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840577</td>\n",
       "      <td>0.842206</td>\n",
       "      <td>0.841588</td>\n",
       "      <td>0.841139</td>\n",
       "      <td>0.840746</td>\n",
       "      <td>0.842720</td>\n",
       "      <td>0.843001</td>\n",
       "      <td>0.841148</td>\n",
       "      <td>0.841894</td>\n",
       "      <td>0.001101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.472838</td>\n",
       "      <td>0.144073</td>\n",
       "      <td>0.026631</td>\n",
       "      <td>0.012716</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>{'min_samples_leaf': 5, 'min_samples_split': 8...</td>\n",
       "      <td>0.817585</td>\n",
       "      <td>0.799394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838668</td>\n",
       "      <td>0.840521</td>\n",
       "      <td>0.838387</td>\n",
       "      <td>0.838612</td>\n",
       "      <td>0.838556</td>\n",
       "      <td>0.839519</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.836487</td>\n",
       "      <td>0.838895</td>\n",
       "      <td>0.001062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.726155</td>\n",
       "      <td>0.173137</td>\n",
       "      <td>0.035404</td>\n",
       "      <td>0.015041</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_leaf': 5, 'min_samples_split': 8...</td>\n",
       "      <td>0.821122</td>\n",
       "      <td>0.800404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839679</td>\n",
       "      <td>0.843160</td>\n",
       "      <td>0.840409</td>\n",
       "      <td>0.838836</td>\n",
       "      <td>0.841307</td>\n",
       "      <td>0.839407</td>\n",
       "      <td>0.840867</td>\n",
       "      <td>0.838902</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.918740</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.041988</td>\n",
       "      <td>0.014606</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>{'min_samples_leaf': 5, 'min_samples_split': 8...</td>\n",
       "      <td>0.817079</td>\n",
       "      <td>0.801415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.843722</td>\n",
       "      <td>0.841027</td>\n",
       "      <td>0.839061</td>\n",
       "      <td>0.841195</td>\n",
       "      <td>0.840418</td>\n",
       "      <td>0.840530</td>\n",
       "      <td>0.839295</td>\n",
       "      <td>0.840704</td>\n",
       "      <td>0.001302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.427357</td>\n",
       "      <td>0.050854</td>\n",
       "      <td>0.030622</td>\n",
       "      <td>0.017521</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>{'min_samples_leaf': 5, 'min_samples_split': 1...</td>\n",
       "      <td>0.817079</td>\n",
       "      <td>0.805963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838443</td>\n",
       "      <td>0.838836</td>\n",
       "      <td>0.838050</td>\n",
       "      <td>0.837713</td>\n",
       "      <td>0.838050</td>\n",
       "      <td>0.837722</td>\n",
       "      <td>0.837217</td>\n",
       "      <td>0.838958</td>\n",
       "      <td>0.838457</td>\n",
       "      <td>0.000946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.670865</td>\n",
       "      <td>0.149941</td>\n",
       "      <td>0.036503</td>\n",
       "      <td>0.013691</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>{'min_samples_leaf': 5, 'min_samples_split': 1...</td>\n",
       "      <td>0.819101</td>\n",
       "      <td>0.806973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.840858</td>\n",
       "      <td>0.838219</td>\n",
       "      <td>0.838668</td>\n",
       "      <td>0.838780</td>\n",
       "      <td>0.837891</td>\n",
       "      <td>0.839407</td>\n",
       "      <td>0.840025</td>\n",
       "      <td>0.839429</td>\n",
       "      <td>0.001049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.778427</td>\n",
       "      <td>0.147023</td>\n",
       "      <td>0.028922</td>\n",
       "      <td>0.007515</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>{'min_samples_leaf': 5, 'min_samples_split': 1...</td>\n",
       "      <td>0.815563</td>\n",
       "      <td>0.804952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840409</td>\n",
       "      <td>0.841195</td>\n",
       "      <td>0.838949</td>\n",
       "      <td>0.840353</td>\n",
       "      <td>0.840016</td>\n",
       "      <td>0.838621</td>\n",
       "      <td>0.840193</td>\n",
       "      <td>0.839407</td>\n",
       "      <td>0.839945</td>\n",
       "      <td>0.000773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.456680      0.112972         0.019945        0.005834   \n",
       "1        0.662929      0.150593         0.031313        0.009652   \n",
       "2        0.814331      0.095977         0.049066        0.016139   \n",
       "3        0.453613      0.049417         0.022341        0.007222   \n",
       "4        0.601403      0.055034         0.029021        0.008303   \n",
       "5        0.820105      0.084816         0.038198        0.010298   \n",
       "6        0.394447      0.050224         0.025631        0.007937   \n",
       "7        0.579649      0.048231         0.025335        0.004420   \n",
       "8        0.661152      0.096084         0.034258        0.011579   \n",
       "9        0.449508      0.132031         0.028425        0.013594   \n",
       "10       0.865386      0.230142         0.047672        0.023994   \n",
       "11       0.794175      0.140766         0.038202        0.012747   \n",
       "12       0.389456      0.065922         0.019746        0.006522   \n",
       "13       0.491684      0.077240         0.023238        0.004907   \n",
       "14       0.649170      0.086499         0.028720        0.007516   \n",
       "15       0.373115      0.066688         0.021349        0.007915   \n",
       "16       0.512334      0.072054         0.024235        0.006479   \n",
       "17       0.685023      0.091781         0.040693        0.011308   \n",
       "18       0.346077      0.057748         0.017250        0.005029   \n",
       "19       0.534474      0.070677         0.022138        0.004806   \n",
       "20       0.674227      0.097629         0.033008        0.011142   \n",
       "21       0.344773      0.059305         0.016355        0.001278   \n",
       "22       0.482218      0.071231         0.024834        0.007796   \n",
       "23       0.687462      0.207572         0.043284        0.023539   \n",
       "24       0.472838      0.144073         0.026631        0.012716   \n",
       "25       0.726155      0.173137         0.035404        0.015041   \n",
       "26       0.918740      0.149600         0.041988        0.014606   \n",
       "27       0.427357      0.050854         0.030622        0.017521   \n",
       "28       0.670865      0.149941         0.036503        0.013691   \n",
       "29       0.778427      0.147023         0.028922        0.007515   \n",
       "\n",
       "   param_min_samples_leaf param_min_samples_split param_n_estimators  \\\n",
       "0                       1                       8                 10   \n",
       "1                       1                       8                 15   \n",
       "2                       1                       8                 20   \n",
       "3                       1                      16                 10   \n",
       "4                       1                      16                 15   \n",
       "5                       1                      16                 20   \n",
       "6                       2                       8                 10   \n",
       "7                       2                       8                 15   \n",
       "8                       2                       8                 20   \n",
       "9                       2                      16                 10   \n",
       "10                      2                      16                 15   \n",
       "11                      2                      16                 20   \n",
       "12                      3                       8                 10   \n",
       "13                      3                       8                 15   \n",
       "14                      3                       8                 20   \n",
       "15                      3                      16                 10   \n",
       "16                      3                      16                 15   \n",
       "17                      3                      16                 20   \n",
       "18                      4                       8                 10   \n",
       "19                      4                       8                 15   \n",
       "20                      4                       8                 20   \n",
       "21                      4                      16                 10   \n",
       "22                      4                      16                 15   \n",
       "23                      4                      16                 20   \n",
       "24                      5                       8                 10   \n",
       "25                      5                       8                 15   \n",
       "26                      5                       8                 20   \n",
       "27                      5                      16                 10   \n",
       "28                      5                      16                 15   \n",
       "29                      5                      16                 20   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'min_samples_leaf': 1, 'min_samples_split': 8...           0.790803   \n",
       "1   {'min_samples_leaf': 1, 'min_samples_split': 8...           0.797372   \n",
       "2   {'min_samples_leaf': 1, 'min_samples_split': 8...           0.798888   \n",
       "3   {'min_samples_leaf': 1, 'min_samples_split': 1...           0.801920   \n",
       "4   {'min_samples_leaf': 1, 'min_samples_split': 1...           0.803436   \n",
       "5   {'min_samples_leaf': 1, 'min_samples_split': 1...           0.800910   \n",
       "6   {'min_samples_leaf': 2, 'min_samples_split': 8...           0.805457   \n",
       "7   {'min_samples_leaf': 2, 'min_samples_split': 8...           0.799899   \n",
       "8   {'min_samples_leaf': 2, 'min_samples_split': 8...           0.804952   \n",
       "9   {'min_samples_leaf': 2, 'min_samples_split': 1...           0.813037   \n",
       "10  {'min_samples_leaf': 2, 'min_samples_split': 1...           0.814553   \n",
       "11  {'min_samples_leaf': 2, 'min_samples_split': 1...           0.815058   \n",
       "12  {'min_samples_leaf': 3, 'min_samples_split': 8...           0.814553   \n",
       "13  {'min_samples_leaf': 3, 'min_samples_split': 8...           0.807984   \n",
       "14  {'min_samples_leaf': 3, 'min_samples_split': 8...           0.818595   \n",
       "15  {'min_samples_leaf': 3, 'min_samples_split': 1...           0.810510   \n",
       "16  {'min_samples_leaf': 3, 'min_samples_split': 1...           0.808994   \n",
       "17  {'min_samples_leaf': 3, 'min_samples_split': 1...           0.812026   \n",
       "18  {'min_samples_leaf': 4, 'min_samples_split': 8...           0.813542   \n",
       "19  {'min_samples_leaf': 4, 'min_samples_split': 8...           0.815058   \n",
       "20  {'min_samples_leaf': 4, 'min_samples_split': 8...           0.811521   \n",
       "21  {'min_samples_leaf': 4, 'min_samples_split': 1...           0.817585   \n",
       "22  {'min_samples_leaf': 4, 'min_samples_split': 1...           0.818595   \n",
       "23  {'min_samples_leaf': 4, 'min_samples_split': 1...           0.820616   \n",
       "24  {'min_samples_leaf': 5, 'min_samples_split': 8...           0.817585   \n",
       "25  {'min_samples_leaf': 5, 'min_samples_split': 8...           0.821122   \n",
       "26  {'min_samples_leaf': 5, 'min_samples_split': 8...           0.817079   \n",
       "27  {'min_samples_leaf': 5, 'min_samples_split': 1...           0.817079   \n",
       "28  {'min_samples_leaf': 5, 'min_samples_split': 1...           0.819101   \n",
       "29  {'min_samples_leaf': 5, 'min_samples_split': 1...           0.815563   \n",
       "\n",
       "    split1_test_score  ...  split2_train_score  split3_train_score  \\\n",
       "0            0.792319  ...            0.869834            0.872642   \n",
       "1            0.796362  ...            0.872248            0.873596   \n",
       "2            0.791814  ...            0.872642            0.875449   \n",
       "3            0.799899  ...            0.856357            0.859614   \n",
       "4            0.798888  ...            0.857143            0.859894   \n",
       "5            0.801415  ...            0.859277            0.860961   \n",
       "6            0.798383  ...            0.857536            0.860400   \n",
       "7            0.800910  ...            0.858322            0.860961   \n",
       "8            0.803941  ...            0.858715            0.860624   \n",
       "9            0.799394  ...            0.848327            0.849450   \n",
       "10           0.804952  ...            0.848214            0.851584   \n",
       "11           0.806468  ...            0.847877            0.851584   \n",
       "12           0.801920  ...            0.850460            0.851190   \n",
       "13           0.805963  ...            0.850685            0.851864   \n",
       "14           0.805457  ...            0.850910            0.852650   \n",
       "15           0.802931  ...            0.844340            0.845013   \n",
       "16           0.806468  ...            0.844620            0.847428   \n",
       "17           0.807479  ...            0.844452            0.846867   \n",
       "18           0.802425  ...            0.843497            0.845743   \n",
       "19           0.805963  ...            0.843722            0.846305   \n",
       "20           0.806468  ...            0.844620            0.847821   \n",
       "21           0.802931  ...            0.839791            0.842150   \n",
       "22           0.803941  ...            0.838949            0.841757   \n",
       "23           0.807984  ...            0.840577            0.842206   \n",
       "24           0.799394  ...            0.838668            0.840521   \n",
       "25           0.800404  ...            0.839679            0.843160   \n",
       "26           0.801415  ...            0.839623            0.843722   \n",
       "27           0.805963  ...            0.838443            0.838836   \n",
       "28           0.806973  ...            0.839623            0.840858   \n",
       "29           0.804952  ...            0.840409            0.841195   \n",
       "\n",
       "    split4_train_score  split5_train_score  split6_train_score  \\\n",
       "0             0.870845            0.870227            0.870788   \n",
       "1             0.873821            0.871799            0.872136   \n",
       "2             0.874775            0.873821            0.873315   \n",
       "3             0.856974            0.857087            0.856862   \n",
       "4             0.858827            0.857648            0.858434   \n",
       "5             0.859558            0.857985            0.858771   \n",
       "6             0.857480            0.855346            0.857087   \n",
       "7             0.858322            0.857929            0.858659   \n",
       "8             0.860344            0.858322            0.859164   \n",
       "9             0.848832            0.847765            0.847428   \n",
       "10            0.849787            0.849000            0.848102   \n",
       "11            0.850966            0.850460            0.848551   \n",
       "12            0.850517            0.847709            0.846530   \n",
       "13            0.851359            0.849787            0.849337   \n",
       "14            0.851303            0.850685            0.849730   \n",
       "15            0.843497            0.843329            0.844677   \n",
       "16            0.844677            0.845013            0.846586   \n",
       "17            0.845856            0.845013            0.846698   \n",
       "18            0.842880            0.842936            0.844789   \n",
       "19            0.843666            0.845294            0.845013   \n",
       "20            0.845463            0.846080            0.845687   \n",
       "21            0.839286            0.839117            0.838331   \n",
       "22            0.840914            0.841027            0.839566   \n",
       "23            0.841588            0.841139            0.840746   \n",
       "24            0.838387            0.838612            0.838556   \n",
       "25            0.840409            0.838836            0.841307   \n",
       "26            0.841027            0.839061            0.841195   \n",
       "27            0.838050            0.837713            0.838050   \n",
       "28            0.838219            0.838668            0.838780   \n",
       "29            0.838949            0.840353            0.840016   \n",
       "\n",
       "    split7_train_score  split8_train_score  split9_train_score  \\\n",
       "0             0.870459            0.871919            0.869167   \n",
       "1             0.871301            0.873716            0.872480   \n",
       "2             0.872312            0.874277            0.873716   \n",
       "3             0.857207            0.858723            0.856870   \n",
       "4             0.858049            0.859228            0.858555   \n",
       "5             0.858274            0.859734            0.860127   \n",
       "6             0.855298            0.858218            0.857151   \n",
       "7             0.856646            0.858948            0.857712   \n",
       "8             0.857375            0.859622            0.858611   \n",
       "9             0.848167            0.848897            0.848784   \n",
       "10            0.849290            0.850132            0.849514   \n",
       "11            0.848840            0.851367            0.849627   \n",
       "12            0.849683            0.847661            0.849402   \n",
       "13            0.850918            0.849121            0.851816   \n",
       "14            0.850918            0.848953            0.851873   \n",
       "15            0.843731            0.844854            0.844741   \n",
       "16            0.844910            0.844854            0.846482   \n",
       "17            0.845584            0.846482            0.846370   \n",
       "18            0.840755            0.844292            0.843057   \n",
       "19            0.842439            0.847381            0.842945   \n",
       "20            0.841709            0.845696            0.844573   \n",
       "21            0.841372            0.840867            0.839744   \n",
       "22            0.841765            0.842439            0.840305   \n",
       "23            0.842720            0.843001            0.841148   \n",
       "24            0.839519            0.838565            0.836487   \n",
       "25            0.839407            0.840867            0.838902   \n",
       "26            0.840418            0.840530            0.839295   \n",
       "27            0.837722            0.837217            0.838958   \n",
       "28            0.837891            0.839407            0.840025   \n",
       "29            0.838621            0.840193            0.839407   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.870920         0.001005  \n",
       "1           0.872750         0.000923  \n",
       "2           0.873969         0.001056  \n",
       "3           0.857392         0.001058  \n",
       "4           0.858762         0.001066  \n",
       "5           0.859599         0.001225  \n",
       "6           0.857639         0.001506  \n",
       "7           0.858836         0.001313  \n",
       "8           0.859509         0.001232  \n",
       "9           0.848587         0.000792  \n",
       "10          0.849514         0.001111  \n",
       "11          0.850115         0.001280  \n",
       "12          0.848891         0.001494  \n",
       "13          0.850581         0.000993  \n",
       "14          0.850811         0.000991  \n",
       "15          0.844146         0.000654  \n",
       "16          0.845538         0.000969  \n",
       "17          0.845915         0.000758  \n",
       "18          0.843618         0.001282  \n",
       "19          0.844943         0.001587  \n",
       "20          0.845600         0.001654  \n",
       "21          0.840462         0.001499  \n",
       "22          0.841130         0.001338  \n",
       "23          0.841894         0.001101  \n",
       "24          0.838895         0.001062  \n",
       "25          0.840361         0.001339  \n",
       "26          0.840704         0.001302  \n",
       "27          0.838457         0.000946  \n",
       "28          0.839429         0.001049  \n",
       "29          0.839945         0.000773  \n",
       "\n",
       "[30 rows x 33 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 33)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_rfc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(cv_result_rfc)\n",
    "df.to_csv('cv_result_rfc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exported the result in csv and short the rank_test_score in ascending order in csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement the GridSearch for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc_param={'C': [0.01,0.1,0.5,1,2,5,10],\n",
    "            'penalty': ['l2'],\n",
    "          'solver':['liblinear','lbfgs','saga']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of combinations= 7*1*3=21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of jobs= 21*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the grid search objects\n",
    "lrc_grid = GridSearchCV(estimator=lrc, \n",
    "                        param_grid=lrc_param,\n",
    "                        scoring='accuracy',\n",
    "                        cv=10,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the data to grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc_grid_fit=lrc_grid.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result_lrc=lrc_grid_fit.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.28104825, 0.69414241, 2.01503353, 0.27067676, 0.7547797 ,\n",
       "        2.12504284, 0.42716384, 0.81452684, 2.61601517, 0.50085835,\n",
       "        0.88180466, 2.09092236, 0.41401324, 0.5605083 , 1.74503152,\n",
       "        0.38527086, 0.56552169, 1.80409346, 0.36981058, 0.57176945,\n",
       "        1.63814776]),\n",
       " 'std_fit_time': array([0.02768776, 0.08957076, 0.32239874, 0.0336067 , 0.06334647,\n",
       "        0.37392686, 0.1516348 , 0.1749037 , 0.34654121, 0.12150061,\n",
       "        0.11714403, 0.19616348, 0.07532369, 0.03307782, 0.227293  ,\n",
       "        0.05832584, 0.03427507, 0.24272811, 0.0469753 , 0.03715675,\n",
       "        0.29424509]),\n",
       " 'mean_score_time': array([0.02094481, 0.00618327, 0.00668273, 0.00658424, 0.00698123,\n",
       "        0.00598278, 0.01136973, 0.00927484, 0.0109709 , 0.0117681 ,\n",
       "        0.00997198, 0.00578675, 0.00638223, 0.00538528, 0.0053853 ,\n",
       "        0.00628402, 0.00614898, 0.00528724, 0.00678375, 0.00588677,\n",
       "        0.005088  ]),\n",
       " 'std_score_time': array([0.01505338, 0.00116371, 0.0033692 , 0.00260808, 0.00413625,\n",
       "        0.00204101, 0.00552065, 0.00401376, 0.00948289, 0.00527498,\n",
       "        0.00614812, 0.00198096, 0.00127762, 0.00101729, 0.001277  ,\n",
       "        0.0006372 , 0.00208578, 0.00077984, 0.00132173, 0.00129836,\n",
       "        0.00246027]),\n",
       " 'param_C': masked_array(data=[0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1, 1,\n",
       "                    1, 2, 2, 2, 5, 5, 5, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'lbfgs', 'saga', 'liblinear', 'lbfgs',\n",
       "                    'saga', 'liblinear', 'lbfgs', 'saga', 'liblinear',\n",
       "                    'lbfgs', 'saga', 'liblinear', 'lbfgs', 'saga',\n",
       "                    'liblinear', 'lbfgs', 'saga', 'liblinear', 'lbfgs',\n",
       "                    'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 0.5, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 0.5, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 0.5, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 2, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 2, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 2, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 5, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 5, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 5, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'saga'}],\n",
       " 'split0_test_score': array([0.8054573 , 0.80899444, 0.80646791, 0.80899444, 0.80697322,\n",
       "        0.80697322, 0.80848914, 0.80899444, 0.80798383, 0.80848914,\n",
       "        0.81051036, 0.80798383, 0.80899444, 0.81202628, 0.80798383,\n",
       "        0.80899444, 0.80899444, 0.80798383, 0.80899444, 0.81152097,\n",
       "        0.80798383]),\n",
       " 'split1_test_score': array([0.79181405, 0.80040424, 0.79029813, 0.79838302, 0.79737241,\n",
       "        0.79282466, 0.79888833, 0.79737241, 0.79231935, 0.79939363,\n",
       "        0.79939363, 0.79231935, 0.80040424, 0.79939363, 0.79231935,\n",
       "        0.79989894, 0.79838302, 0.79231935, 0.79888833, 0.79888833,\n",
       "        0.79231935]),\n",
       " 'split2_test_score': array([0.82162708, 0.81303689, 0.81960586, 0.81758464, 0.82011117,\n",
       "        0.81758464, 0.81657403, 0.81960586, 0.81808994, 0.81657403,\n",
       "        0.82162708, 0.81758464, 0.81707933, 0.82061647, 0.81758464,\n",
       "        0.81758464, 0.82162708, 0.81758464, 0.81758464, 0.82162708,\n",
       "        0.81758464]),\n",
       " 'split3_test_score': array([0.80141486, 0.79787772, 0.79838302, 0.79888833, 0.79939363,\n",
       "        0.7968671 , 0.79888833, 0.80141486, 0.79737241, 0.79989894,\n",
       "        0.80040424, 0.79737241, 0.80090955, 0.80090955, 0.7968671 ,\n",
       "        0.80090955, 0.79939363, 0.7968671 , 0.80090955, 0.80090955,\n",
       "        0.7968671 ]),\n",
       " 'split4_test_score': array([0.81707933, 0.82112178, 0.81808994, 0.82465892, 0.8226377 ,\n",
       "        0.81960586, 0.82011117, 0.823143  , 0.81910056, 0.82011117,\n",
       "        0.82516422, 0.81859525, 0.82011117, 0.8226377 , 0.81859525,\n",
       "        0.82162708, 0.823143  , 0.81859525, 0.82112178, 0.82011117,\n",
       "        0.81859525]),\n",
       " 'split5_test_score': array([0.81606872, 0.81505811, 0.81707933, 0.81758464, 0.81505811,\n",
       "        0.8145528 , 0.81606872, 0.81556342, 0.81505811, 0.81606872,\n",
       "        0.81556342, 0.81505811, 0.81606872, 0.8140475 , 0.81505811,\n",
       "        0.81657403, 0.8145528 , 0.81505811, 0.81707933, 0.81505811,\n",
       "        0.81505811]),\n",
       " 'split6_test_score': array([0.82061647, 0.81303689, 0.82213239, 0.82516422, 0.81859525,\n",
       "        0.82364831, 0.82011117, 0.81758464, 0.8226377 , 0.81960586,\n",
       "        0.82011117, 0.8226377 , 0.82011117, 0.81808994, 0.8226377 ,\n",
       "        0.82011117, 0.82011117, 0.8226377 , 0.82011117, 0.81910056,\n",
       "        0.8226377 ]),\n",
       " 'split7_test_score': array([0.81597573, 0.82153691, 0.81597573, 0.82608696, 0.82305359,\n",
       "        0.81799798, 0.82406471, 0.82406471, 0.81799798, 0.82406471,\n",
       "        0.82457027, 0.81799798, 0.82406471, 0.82305359, 0.81799798,\n",
       "        0.82406471, 0.82608696, 0.81799798, 0.82406471, 0.82406471,\n",
       "        0.81799798]),\n",
       " 'split8_test_score': array([0.81193124, 0.81749242, 0.81294237, 0.81597573, 0.8190091 ,\n",
       "        0.81142568, 0.81799798, 0.81951466, 0.81193124, 0.8190091 ,\n",
       "        0.81799798, 0.81193124, 0.8190091 , 0.81951466, 0.81193124,\n",
       "        0.8190091 , 0.81951466, 0.81193124, 0.8190091 , 0.81648129,\n",
       "        0.81193124]),\n",
       " 'split9_test_score': array([0.80738119, 0.80788675, 0.80839232, 0.8124368 , 0.80839232,\n",
       "        0.80535895, 0.81041456, 0.80889788, 0.80485339, 0.81041456,\n",
       "        0.80788675, 0.80485339, 0.809909  , 0.80738119, 0.80485339,\n",
       "        0.81041456, 0.80637007, 0.80485339, 0.81041456, 0.80889788,\n",
       "        0.80485339]),\n",
       " 'mean_test_score': array([0.8109366 , 0.81164461, 0.8109367 , 0.81457577, 0.81305965,\n",
       "        0.81068392, 0.81316081, 0.81361559, 0.81073445, 0.81336299,\n",
       "        0.81432291, 0.81063339, 0.81366614, 0.81376705, 0.81058286,\n",
       "        0.81391882, 0.81381768, 0.81058286, 0.81381776, 0.81366596,\n",
       "        0.81058286]),\n",
       " 'std_test_score': array([0.00892995, 0.00757904, 0.00963744, 0.00954142, 0.00896132,\n",
       "        0.00957232, 0.00834139, 0.00864   , 0.00947882, 0.00810814,\n",
       "        0.00892757, 0.00939681, 0.00782129, 0.00824235, 0.00946906,\n",
       "        0.00805871, 0.00946626, 0.00946906, 0.00821029, 0.00812953,\n",
       "        0.00946906]),\n",
       " 'rank_test_score': array([15, 13, 14,  1, 12, 17, 11,  9, 16, 10,  2, 18,  7,  6, 19,  3,  5,\n",
       "        19,  4,  8, 19]),\n",
       " 'split0_train_score': array([0.81165768, 0.81294924, 0.81092767, 0.81564465, 0.81396002,\n",
       "        0.81103998, 0.81519542, 0.81457772, 0.81070305, 0.81474618,\n",
       "        0.81480234, 0.81059075, 0.81519542, 0.81469003, 0.81059075,\n",
       "        0.81502695, 0.81469003, 0.81053459, 0.81525157, 0.81457772,\n",
       "        0.81053459]),\n",
       " 'split1_train_score': array([0.81272462, 0.81345463, 0.81317385, 0.81676774, 0.81513926,\n",
       "        0.81238769, 0.8162062 , 0.81553235, 0.81255615, 0.81598158,\n",
       "        0.81575696, 0.81255615, 0.81536388, 0.81586927, 0.81255615,\n",
       "        0.81530773, 0.81530773, 0.81255615, 0.81536388, 0.81570081,\n",
       "        0.81255615]),\n",
       " 'split2_train_score': array([0.81008535, 0.81154537, 0.80924304, 0.81452156, 0.81272462,\n",
       "        0.8100292 , 0.81412848, 0.81424079, 0.8100292 , 0.81429695,\n",
       "        0.81384771, 0.80997305, 0.81424079, 0.81317385, 0.8100292 ,\n",
       "        0.8143531 , 0.81356694, 0.8100292 , 0.81446541, 0.81384771,\n",
       "        0.8100292 ]),\n",
       " 'split3_train_score': array([0.81244385, 0.81283693, 0.81193845, 0.81643082, 0.81491465,\n",
       "        0.81233154, 0.81553235, 0.81564465, 0.81233154, 0.81553235,\n",
       "        0.81542004, 0.81238769, 0.81530773, 0.8155885 , 0.81238769,\n",
       "        0.81598158, 0.81643082, 0.81238769, 0.81603774, 0.81609389,\n",
       "        0.81238769]),\n",
       " 'split4_train_score': array([0.8106469 , 0.80884996, 0.80974843, 0.81345463, 0.81323001,\n",
       "        0.81014151, 0.81396002, 0.81283693, 0.81036613, 0.81362309,\n",
       "        0.81221923, 0.81036613, 0.81334232, 0.81266846, 0.81042228,\n",
       "        0.81367925, 0.81412848, 0.81053459, 0.81379155, 0.81199461,\n",
       "        0.81053459]),\n",
       " 'split5_train_score': array([0.81070305, 0.80969227, 0.81014151, 0.81485849, 0.81351078,\n",
       "        0.81030997, 0.81379155, 0.81306155, 0.81030997, 0.81351078,\n",
       "        0.81384771, 0.81042228, 0.81356694, 0.81429695, 0.81047844,\n",
       "        0.81345463, 0.81255615, 0.81042228, 0.81339847, 0.81446541,\n",
       "        0.81042228]),\n",
       " 'split6_train_score': array([0.80980458, 0.81210692, 0.80935535, 0.81356694, 0.81328616,\n",
       "        0.80952381, 0.81356694, 0.81345463, 0.80924304, 0.81339847,\n",
       "        0.81362309, 0.80924304, 0.81334232, 0.81306155, 0.80924304,\n",
       "        0.81334232, 0.81345463, 0.80924304, 0.8131177 , 0.81396002,\n",
       "        0.80929919]),\n",
       " 'split7_train_score': array([0.81020832, 0.8111629 , 0.81003987, 0.8133528 , 0.81110674,\n",
       "        0.80981526, 0.81307204, 0.81133135, 0.81003987, 0.81273513,\n",
       "        0.81312819, 0.81003987, 0.81301589, 0.81307204, 0.81003987,\n",
       "        0.8132405 , 0.81413892, 0.80998372, 0.8133528 , 0.81402662,\n",
       "        0.80998372]),\n",
       " 'split8_train_score': array([0.81082599, 0.81037678, 0.81043293, 0.81447583, 0.81312819,\n",
       "        0.81082599, 0.81397046, 0.81436352, 0.81071368, 0.81374586,\n",
       "        0.81402662, 0.81065753, 0.81295974, 0.8133528 , 0.81065753,\n",
       "        0.81301589, 0.81397046, 0.81071368, 0.81279129, 0.81340895,\n",
       "        0.81071368]),\n",
       " 'split9_train_score': array([0.8113875 , 0.81234207, 0.81133135, 0.81503734, 0.81464428,\n",
       "        0.81133135, 0.81447583, 0.81458813, 0.81133135, 0.81391431,\n",
       "        0.81503734, 0.8112752 , 0.81447583, 0.81413892, 0.8112752 ,\n",
       "        0.81520579, 0.81514964, 0.8111629 , 0.81503734, 0.81425122,\n",
       "        0.8111629 ]),\n",
       " 'mean_train_score': array([0.81104878, 0.81153171, 0.81063324, 0.81481108, 0.81356447,\n",
       "        0.81077363, 0.81438993, 0.81396316, 0.8107624 , 0.81414847,\n",
       "        0.81417092, 0.81075117, 0.81408108, 0.81399124, 0.81076801,\n",
       "        0.81426077, 0.81433938, 0.81075678, 0.81426078, 0.81423269,\n",
       "        0.8107624 ]),\n",
       " 'std_train_score': array([0.0009356 , 0.00142981, 0.00117111, 0.00113627, 0.00112932,\n",
       "        0.00095217, 0.00091986, 0.00124747, 0.00098687, 0.00095469,\n",
       "        0.00103206, 0.00099436, 0.00091221, 0.00105908, 0.00098624,\n",
       "        0.00099841, 0.00104266, 0.00098455, 0.00106091, 0.00108377,\n",
       "        0.00097603])}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_lrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covert the results in data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result_lrc=pd.DataFrame.from_dict(lrc_grid_fit.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.281048</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.020945</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'liblin...</td>\n",
       "      <td>0.805457</td>\n",
       "      <td>0.791814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810085</td>\n",
       "      <td>0.812444</td>\n",
       "      <td>0.810647</td>\n",
       "      <td>0.810703</td>\n",
       "      <td>0.809805</td>\n",
       "      <td>0.810208</td>\n",
       "      <td>0.810826</td>\n",
       "      <td>0.811388</td>\n",
       "      <td>0.811049</td>\n",
       "      <td>0.000936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.694142</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>0.006183</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.808994</td>\n",
       "      <td>0.800404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811545</td>\n",
       "      <td>0.812837</td>\n",
       "      <td>0.808850</td>\n",
       "      <td>0.809692</td>\n",
       "      <td>0.812107</td>\n",
       "      <td>0.811163</td>\n",
       "      <td>0.810377</td>\n",
       "      <td>0.812342</td>\n",
       "      <td>0.811532</td>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.015034</td>\n",
       "      <td>0.322399</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.806468</td>\n",
       "      <td>0.790298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809243</td>\n",
       "      <td>0.811938</td>\n",
       "      <td>0.809748</td>\n",
       "      <td>0.810142</td>\n",
       "      <td>0.809355</td>\n",
       "      <td>0.810040</td>\n",
       "      <td>0.810433</td>\n",
       "      <td>0.811331</td>\n",
       "      <td>0.810633</td>\n",
       "      <td>0.001171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.270677</td>\n",
       "      <td>0.033607</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.808994</td>\n",
       "      <td>0.798383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814522</td>\n",
       "      <td>0.816431</td>\n",
       "      <td>0.813455</td>\n",
       "      <td>0.814858</td>\n",
       "      <td>0.813567</td>\n",
       "      <td>0.813353</td>\n",
       "      <td>0.814476</td>\n",
       "      <td>0.815037</td>\n",
       "      <td>0.814811</td>\n",
       "      <td>0.001136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.754780</td>\n",
       "      <td>0.063346</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.806973</td>\n",
       "      <td>0.797372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812725</td>\n",
       "      <td>0.814915</td>\n",
       "      <td>0.813230</td>\n",
       "      <td>0.813511</td>\n",
       "      <td>0.813286</td>\n",
       "      <td>0.811107</td>\n",
       "      <td>0.813128</td>\n",
       "      <td>0.814644</td>\n",
       "      <td>0.813564</td>\n",
       "      <td>0.001129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.125043</td>\n",
       "      <td>0.373927</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.806973</td>\n",
       "      <td>0.792825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810029</td>\n",
       "      <td>0.812332</td>\n",
       "      <td>0.810142</td>\n",
       "      <td>0.810310</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.809815</td>\n",
       "      <td>0.810826</td>\n",
       "      <td>0.811331</td>\n",
       "      <td>0.810774</td>\n",
       "      <td>0.000952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.427164</td>\n",
       "      <td>0.151635</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.5, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.808489</td>\n",
       "      <td>0.798888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814128</td>\n",
       "      <td>0.815532</td>\n",
       "      <td>0.813960</td>\n",
       "      <td>0.813792</td>\n",
       "      <td>0.813567</td>\n",
       "      <td>0.813072</td>\n",
       "      <td>0.813970</td>\n",
       "      <td>0.814476</td>\n",
       "      <td>0.814390</td>\n",
       "      <td>0.000920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.814527</td>\n",
       "      <td>0.174904</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.5, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.808994</td>\n",
       "      <td>0.797372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814241</td>\n",
       "      <td>0.815645</td>\n",
       "      <td>0.812837</td>\n",
       "      <td>0.813062</td>\n",
       "      <td>0.813455</td>\n",
       "      <td>0.811331</td>\n",
       "      <td>0.814364</td>\n",
       "      <td>0.814588</td>\n",
       "      <td>0.813963</td>\n",
       "      <td>0.001247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.616015</td>\n",
       "      <td>0.346541</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>0.009483</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 0.5, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.807984</td>\n",
       "      <td>0.792319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810029</td>\n",
       "      <td>0.812332</td>\n",
       "      <td>0.810366</td>\n",
       "      <td>0.810310</td>\n",
       "      <td>0.809243</td>\n",
       "      <td>0.810040</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>0.811331</td>\n",
       "      <td>0.810762</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.500858</td>\n",
       "      <td>0.121501</td>\n",
       "      <td>0.011768</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.808489</td>\n",
       "      <td>0.799394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814297</td>\n",
       "      <td>0.815532</td>\n",
       "      <td>0.813623</td>\n",
       "      <td>0.813511</td>\n",
       "      <td>0.813398</td>\n",
       "      <td>0.812735</td>\n",
       "      <td>0.813746</td>\n",
       "      <td>0.813914</td>\n",
       "      <td>0.814148</td>\n",
       "      <td>0.000955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.881805</td>\n",
       "      <td>0.117144</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>0.006148</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.810510</td>\n",
       "      <td>0.799394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813848</td>\n",
       "      <td>0.815420</td>\n",
       "      <td>0.812219</td>\n",
       "      <td>0.813848</td>\n",
       "      <td>0.813623</td>\n",
       "      <td>0.813128</td>\n",
       "      <td>0.814027</td>\n",
       "      <td>0.815037</td>\n",
       "      <td>0.814171</td>\n",
       "      <td>0.001032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.090922</td>\n",
       "      <td>0.196163</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.807984</td>\n",
       "      <td>0.792319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809973</td>\n",
       "      <td>0.812388</td>\n",
       "      <td>0.810366</td>\n",
       "      <td>0.810422</td>\n",
       "      <td>0.809243</td>\n",
       "      <td>0.810040</td>\n",
       "      <td>0.810658</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.810751</td>\n",
       "      <td>0.000994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.414013</td>\n",
       "      <td>0.075324</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>2</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 2, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.808994</td>\n",
       "      <td>0.800404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814241</td>\n",
       "      <td>0.815308</td>\n",
       "      <td>0.813342</td>\n",
       "      <td>0.813567</td>\n",
       "      <td>0.813342</td>\n",
       "      <td>0.813016</td>\n",
       "      <td>0.812960</td>\n",
       "      <td>0.814476</td>\n",
       "      <td>0.814081</td>\n",
       "      <td>0.000912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.560508</td>\n",
       "      <td>0.033078</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>2</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 2, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.812026</td>\n",
       "      <td>0.799394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813174</td>\n",
       "      <td>0.815588</td>\n",
       "      <td>0.812668</td>\n",
       "      <td>0.814297</td>\n",
       "      <td>0.813062</td>\n",
       "      <td>0.813072</td>\n",
       "      <td>0.813353</td>\n",
       "      <td>0.814139</td>\n",
       "      <td>0.813991</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.745032</td>\n",
       "      <td>0.227293</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>2</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 2, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.807984</td>\n",
       "      <td>0.792319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810029</td>\n",
       "      <td>0.812388</td>\n",
       "      <td>0.810422</td>\n",
       "      <td>0.810478</td>\n",
       "      <td>0.809243</td>\n",
       "      <td>0.810040</td>\n",
       "      <td>0.810658</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.810768</td>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.385271</td>\n",
       "      <td>0.058326</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>5</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 5, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.808994</td>\n",
       "      <td>0.799899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814353</td>\n",
       "      <td>0.815982</td>\n",
       "      <td>0.813679</td>\n",
       "      <td>0.813455</td>\n",
       "      <td>0.813342</td>\n",
       "      <td>0.813240</td>\n",
       "      <td>0.813016</td>\n",
       "      <td>0.815206</td>\n",
       "      <td>0.814261</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.565522</td>\n",
       "      <td>0.034275</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>5</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 5, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.808994</td>\n",
       "      <td>0.798383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813567</td>\n",
       "      <td>0.816431</td>\n",
       "      <td>0.814128</td>\n",
       "      <td>0.812556</td>\n",
       "      <td>0.813455</td>\n",
       "      <td>0.814139</td>\n",
       "      <td>0.813970</td>\n",
       "      <td>0.815150</td>\n",
       "      <td>0.814339</td>\n",
       "      <td>0.001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.804093</td>\n",
       "      <td>0.242728</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>5</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 5, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.807984</td>\n",
       "      <td>0.792319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810029</td>\n",
       "      <td>0.812388</td>\n",
       "      <td>0.810535</td>\n",
       "      <td>0.810422</td>\n",
       "      <td>0.809243</td>\n",
       "      <td>0.809984</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>0.811163</td>\n",
       "      <td>0.810757</td>\n",
       "      <td>0.000985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.369811</td>\n",
       "      <td>0.046975</td>\n",
       "      <td>0.006784</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.808994</td>\n",
       "      <td>0.798888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814465</td>\n",
       "      <td>0.816038</td>\n",
       "      <td>0.813792</td>\n",
       "      <td>0.813398</td>\n",
       "      <td>0.813118</td>\n",
       "      <td>0.813353</td>\n",
       "      <td>0.812791</td>\n",
       "      <td>0.815037</td>\n",
       "      <td>0.814261</td>\n",
       "      <td>0.001061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.571769</td>\n",
       "      <td>0.037157</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.811521</td>\n",
       "      <td>0.798888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813848</td>\n",
       "      <td>0.816094</td>\n",
       "      <td>0.811995</td>\n",
       "      <td>0.814465</td>\n",
       "      <td>0.813960</td>\n",
       "      <td>0.814027</td>\n",
       "      <td>0.813409</td>\n",
       "      <td>0.814251</td>\n",
       "      <td>0.814233</td>\n",
       "      <td>0.001084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.638148</td>\n",
       "      <td>0.294245</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'saga'}</td>\n",
       "      <td>0.807984</td>\n",
       "      <td>0.792319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810029</td>\n",
       "      <td>0.812388</td>\n",
       "      <td>0.810535</td>\n",
       "      <td>0.810422</td>\n",
       "      <td>0.809299</td>\n",
       "      <td>0.809984</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>0.811163</td>\n",
       "      <td>0.810762</td>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.281048      0.027688         0.020945        0.015053    0.01   \n",
       "1        0.694142      0.089571         0.006183        0.001164    0.01   \n",
       "2        2.015034      0.322399         0.006683        0.003369    0.01   \n",
       "3        0.270677      0.033607         0.006584        0.002608     0.1   \n",
       "4        0.754780      0.063346         0.006981        0.004136     0.1   \n",
       "5        2.125043      0.373927         0.005983        0.002041     0.1   \n",
       "6        0.427164      0.151635         0.011370        0.005521     0.5   \n",
       "7        0.814527      0.174904         0.009275        0.004014     0.5   \n",
       "8        2.616015      0.346541         0.010971        0.009483     0.5   \n",
       "9        0.500858      0.121501         0.011768        0.005275       1   \n",
       "10       0.881805      0.117144         0.009972        0.006148       1   \n",
       "11       2.090922      0.196163         0.005787        0.001981       1   \n",
       "12       0.414013      0.075324         0.006382        0.001278       2   \n",
       "13       0.560508      0.033078         0.005385        0.001017       2   \n",
       "14       1.745032      0.227293         0.005385        0.001277       2   \n",
       "15       0.385271      0.058326         0.006284        0.000637       5   \n",
       "16       0.565522      0.034275         0.006149        0.002086       5   \n",
       "17       1.804093      0.242728         0.005287        0.000780       5   \n",
       "18       0.369811      0.046975         0.006784        0.001322      10   \n",
       "19       0.571769      0.037157         0.005887        0.001298      10   \n",
       "20       1.638148      0.294245         0.005088        0.002460      10   \n",
       "\n",
       "   param_penalty param_solver  \\\n",
       "0             l2    liblinear   \n",
       "1             l2        lbfgs   \n",
       "2             l2         saga   \n",
       "3             l2    liblinear   \n",
       "4             l2        lbfgs   \n",
       "5             l2         saga   \n",
       "6             l2    liblinear   \n",
       "7             l2        lbfgs   \n",
       "8             l2         saga   \n",
       "9             l2    liblinear   \n",
       "10            l2        lbfgs   \n",
       "11            l2         saga   \n",
       "12            l2    liblinear   \n",
       "13            l2        lbfgs   \n",
       "14            l2         saga   \n",
       "15            l2    liblinear   \n",
       "16            l2        lbfgs   \n",
       "17            l2         saga   \n",
       "18            l2    liblinear   \n",
       "19            l2        lbfgs   \n",
       "20            l2         saga   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'C': 0.01, 'penalty': 'l2', 'solver': 'liblin...           0.805457   \n",
       "1     {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}           0.808994   \n",
       "2      {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}           0.806468   \n",
       "3   {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...           0.808994   \n",
       "4      {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}           0.806973   \n",
       "5       {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}           0.806973   \n",
       "6   {'C': 0.5, 'penalty': 'l2', 'solver': 'libline...           0.808489   \n",
       "7      {'C': 0.5, 'penalty': 'l2', 'solver': 'lbfgs'}           0.808994   \n",
       "8       {'C': 0.5, 'penalty': 'l2', 'solver': 'saga'}           0.807984   \n",
       "9    {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}           0.808489   \n",
       "10       {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}           0.810510   \n",
       "11        {'C': 1, 'penalty': 'l2', 'solver': 'saga'}           0.807984   \n",
       "12   {'C': 2, 'penalty': 'l2', 'solver': 'liblinear'}           0.808994   \n",
       "13       {'C': 2, 'penalty': 'l2', 'solver': 'lbfgs'}           0.812026   \n",
       "14        {'C': 2, 'penalty': 'l2', 'solver': 'saga'}           0.807984   \n",
       "15   {'C': 5, 'penalty': 'l2', 'solver': 'liblinear'}           0.808994   \n",
       "16       {'C': 5, 'penalty': 'l2', 'solver': 'lbfgs'}           0.808994   \n",
       "17        {'C': 5, 'penalty': 'l2', 'solver': 'saga'}           0.807984   \n",
       "18  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}           0.808994   \n",
       "19      {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}           0.811521   \n",
       "20       {'C': 10, 'penalty': 'l2', 'solver': 'saga'}           0.807984   \n",
       "\n",
       "    split1_test_score  ...  split2_train_score  split3_train_score  \\\n",
       "0            0.791814  ...            0.810085            0.812444   \n",
       "1            0.800404  ...            0.811545            0.812837   \n",
       "2            0.790298  ...            0.809243            0.811938   \n",
       "3            0.798383  ...            0.814522            0.816431   \n",
       "4            0.797372  ...            0.812725            0.814915   \n",
       "5            0.792825  ...            0.810029            0.812332   \n",
       "6            0.798888  ...            0.814128            0.815532   \n",
       "7            0.797372  ...            0.814241            0.815645   \n",
       "8            0.792319  ...            0.810029            0.812332   \n",
       "9            0.799394  ...            0.814297            0.815532   \n",
       "10           0.799394  ...            0.813848            0.815420   \n",
       "11           0.792319  ...            0.809973            0.812388   \n",
       "12           0.800404  ...            0.814241            0.815308   \n",
       "13           0.799394  ...            0.813174            0.815588   \n",
       "14           0.792319  ...            0.810029            0.812388   \n",
       "15           0.799899  ...            0.814353            0.815982   \n",
       "16           0.798383  ...            0.813567            0.816431   \n",
       "17           0.792319  ...            0.810029            0.812388   \n",
       "18           0.798888  ...            0.814465            0.816038   \n",
       "19           0.798888  ...            0.813848            0.816094   \n",
       "20           0.792319  ...            0.810029            0.812388   \n",
       "\n",
       "    split4_train_score  split5_train_score  split6_train_score  \\\n",
       "0             0.810647            0.810703            0.809805   \n",
       "1             0.808850            0.809692            0.812107   \n",
       "2             0.809748            0.810142            0.809355   \n",
       "3             0.813455            0.814858            0.813567   \n",
       "4             0.813230            0.813511            0.813286   \n",
       "5             0.810142            0.810310            0.809524   \n",
       "6             0.813960            0.813792            0.813567   \n",
       "7             0.812837            0.813062            0.813455   \n",
       "8             0.810366            0.810310            0.809243   \n",
       "9             0.813623            0.813511            0.813398   \n",
       "10            0.812219            0.813848            0.813623   \n",
       "11            0.810366            0.810422            0.809243   \n",
       "12            0.813342            0.813567            0.813342   \n",
       "13            0.812668            0.814297            0.813062   \n",
       "14            0.810422            0.810478            0.809243   \n",
       "15            0.813679            0.813455            0.813342   \n",
       "16            0.814128            0.812556            0.813455   \n",
       "17            0.810535            0.810422            0.809243   \n",
       "18            0.813792            0.813398            0.813118   \n",
       "19            0.811995            0.814465            0.813960   \n",
       "20            0.810535            0.810422            0.809299   \n",
       "\n",
       "    split7_train_score  split8_train_score  split9_train_score  \\\n",
       "0             0.810208            0.810826            0.811388   \n",
       "1             0.811163            0.810377            0.812342   \n",
       "2             0.810040            0.810433            0.811331   \n",
       "3             0.813353            0.814476            0.815037   \n",
       "4             0.811107            0.813128            0.814644   \n",
       "5             0.809815            0.810826            0.811331   \n",
       "6             0.813072            0.813970            0.814476   \n",
       "7             0.811331            0.814364            0.814588   \n",
       "8             0.810040            0.810714            0.811331   \n",
       "9             0.812735            0.813746            0.813914   \n",
       "10            0.813128            0.814027            0.815037   \n",
       "11            0.810040            0.810658            0.811275   \n",
       "12            0.813016            0.812960            0.814476   \n",
       "13            0.813072            0.813353            0.814139   \n",
       "14            0.810040            0.810658            0.811275   \n",
       "15            0.813240            0.813016            0.815206   \n",
       "16            0.814139            0.813970            0.815150   \n",
       "17            0.809984            0.810714            0.811163   \n",
       "18            0.813353            0.812791            0.815037   \n",
       "19            0.814027            0.813409            0.814251   \n",
       "20            0.809984            0.810714            0.811163   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.811049         0.000936  \n",
       "1           0.811532         0.001430  \n",
       "2           0.810633         0.001171  \n",
       "3           0.814811         0.001136  \n",
       "4           0.813564         0.001129  \n",
       "5           0.810774         0.000952  \n",
       "6           0.814390         0.000920  \n",
       "7           0.813963         0.001247  \n",
       "8           0.810762         0.000987  \n",
       "9           0.814148         0.000955  \n",
       "10          0.814171         0.001032  \n",
       "11          0.810751         0.000994  \n",
       "12          0.814081         0.000912  \n",
       "13          0.813991         0.001059  \n",
       "14          0.810768         0.000986  \n",
       "15          0.814261         0.000998  \n",
       "16          0.814339         0.001043  \n",
       "17          0.810757         0.000985  \n",
       "18          0.814261         0.001061  \n",
       "19          0.814233         0.001084  \n",
       "20          0.810762         0.000976  \n",
       "\n",
       "[21 rows x 33 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_lrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(cv_result_lrc)\n",
    "df.to_csv('cv_result_lrc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement the GridSearch for Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameter for support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_param={'C': [0.01,0.1,0.5,1,2,5,10],\n",
    "            'kernel': ['rbf','linear'],\n",
    "          'gamma':[0.1,0.25,0.5,1,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the parameter results in 7*2*5=70 different combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CV=10 for 70 different combinations mean 700 jobs/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the grid search objects\n",
    "svc_grid = GridSearchCV(estimator=svc, \n",
    "                        param_grid=svc_param,\n",
    "                        scoring='accuracy',\n",
    "                        cv=10,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the data to grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_grid_fit=svc_grid.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result_svc=svc_grid_fit.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([   41.70601852,    37.57959447,    40.05763092,    38.58436844,\n",
       "           57.38280053,    37.22357903,    72.92646639,    34.58094566,\n",
       "           89.98974562,    33.82671378,    35.5294312 ,    46.16309614,\n",
       "           41.64465389,    46.34740345,    63.94713244,    43.67934613,\n",
       "           90.85779889,    41.71572883,   133.61181278,    40.08246064,\n",
       "           31.60671899,    76.82221236,    36.58339827,    76.47803891,\n",
       "           73.5399507 ,    76.51566916,   105.22790399,    71.66398299,\n",
       "          149.65542171,    72.3970345 ,    30.13881729,   113.56551971,\n",
       "           53.14344594,   109.70718751,    79.27706966,   117.68642011,\n",
       "          115.55160491,   114.71986372,   151.34661772,   117.90265114,\n",
       "           33.48799736,   212.32206838,    68.51880541,   213.9950022 ,\n",
       "          101.25822172,   212.52162554,   115.00451655,   211.30782766,\n",
       "          155.43856766,   201.78652396,    38.34449923,   418.52680507,\n",
       "           87.88139217,   413.40430143,   106.83136601,   410.6645689 ,\n",
       "          113.7412204 ,   414.21583145,   151.65303469, 21876.15069182,\n",
       "           65.40538487,   650.06214166,    96.49824524,   638.5281702 ,\n",
       "          100.97979546,   643.09750693,    98.03335001,   654.04651937,\n",
       "          131.02412174,   639.16869931]),\n",
       " 'std_fit_time': array([1.61996758e+00, 1.39051388e+00, 2.15776561e+00, 4.62883258e+00,\n",
       "        8.02205707e+00, 3.72521961e+00, 5.30891557e+00, 2.38882993e+00,\n",
       "        6.58907196e+00, 2.29117919e+00, 2.36346717e+00, 2.12099597e+00,\n",
       "        9.49292082e-01, 2.92061350e+00, 5.74094093e+00, 2.82648108e+00,\n",
       "        4.27777987e+00, 2.29864308e+00, 8.74213280e+00, 2.52114639e+00,\n",
       "        1.14518958e+00, 4.58339641e+00, 1.97075197e+00, 4.45661263e+00,\n",
       "        5.73536183e+00, 4.62153892e+00, 2.84249659e+00, 2.88383049e+00,\n",
       "        6.06925317e+00, 3.86060671e+00, 2.77522018e+00, 4.95491270e+00,\n",
       "        7.40931946e+00, 3.15150065e+00, 3.27444820e+00, 4.99680703e+00,\n",
       "        4.71309879e+00, 5.16465009e+00, 4.81594005e+00, 5.08649085e+00,\n",
       "        2.02940719e+00, 1.00456668e+01, 8.92454259e+00, 1.03219590e+01,\n",
       "        3.85022164e+00, 1.02924096e+01, 3.34847640e+00, 9.96004848e+00,\n",
       "        1.24885193e+01, 8.27449348e+00, 1.52909861e+00, 9.15705562e+00,\n",
       "        7.69890537e+00, 1.30084647e+01, 4.43602758e+00, 1.16301736e+01,\n",
       "        4.65406322e+00, 7.87539713e+00, 8.11452101e+00, 8.98199858e+03,\n",
       "        8.47893943e+00, 1.88777042e+01, 8.48447132e+00, 1.39350171e+01,\n",
       "        1.20801478e+01, 1.74603489e+01, 4.72120913e+00, 2.60452987e+01,\n",
       "        1.03752852e+01, 9.48958483e+01]),\n",
       " 'mean_score_time': array([1.96954739, 1.18645275, 2.42386458, 1.41263311, 3.1330833 ,\n",
       "        1.27225561, 3.21284709, 1.14136562, 4.56594782, 1.12916286,\n",
       "        2.03498344, 1.02134094, 2.27860925, 1.04772303, 2.58366966,\n",
       "        0.88599265, 3.03760834, 0.86085961, 5.08521905, 0.82810838,\n",
       "        1.6478019 , 0.77568905, 1.88632646, 0.81657596, 2.34763796,\n",
       "        0.81960707, 3.03699934, 0.74077759, 4.24303017, 0.71824598,\n",
       "        1.52623384, 0.73503606, 1.71842339, 0.75937645, 2.31245332,\n",
       "        0.71340091, 3.01077135, 0.73057547, 4.51409435, 0.75555561,\n",
       "        1.56415722, 0.77487404, 1.79005432, 0.76341002, 2.28056672,\n",
       "        0.75788352, 3.12357435, 0.71145015, 4.28955748, 0.72494657,\n",
       "        1.35480363, 0.7120384 , 1.63435111, 0.72610471, 2.06625383,\n",
       "        0.70729053, 2.92515626, 0.67334237, 4.26433291, 0.70657315,\n",
       "        1.30088446, 0.61576169, 1.40076866, 0.60170047, 1.74003026,\n",
       "        0.59621234, 2.53584573, 0.59376287, 3.70256424, 0.52256176]),\n",
       " 'std_score_time': array([0.20110904, 0.08567388, 0.40638579, 0.36793248, 0.93487023,\n",
       "        0.2373859 , 0.38117348, 0.19523834, 0.2561168 , 0.11930762,\n",
       "        0.15440387, 0.09902544, 0.13356123, 0.13333492, 0.07281209,\n",
       "        0.10715079, 0.11081602, 0.12921398, 0.686471  , 0.10912028,\n",
       "        0.11204183, 0.08373248, 0.13440521, 0.06147851, 0.11992139,\n",
       "        0.07759267, 0.19701171, 0.08339846, 0.21351568, 0.05007346,\n",
       "        0.10702472, 0.09376578, 0.10538471, 0.11357498, 0.23511638,\n",
       "        0.04956238, 0.15429787, 0.0625072 , 0.17978299, 0.06377684,\n",
       "        0.10360833, 0.05365126, 0.1042851 , 0.05372885, 0.0885863 ,\n",
       "        0.02851928, 0.12704589, 0.03774325, 0.15509571, 0.01389118,\n",
       "        0.04475254, 0.04617163, 0.0485057 , 0.08796401, 0.05277957,\n",
       "        0.04642591, 0.10936858, 0.0308375 , 0.19924098, 0.10677904,\n",
       "        0.11720913, 0.04322193, 0.10354883, 0.02432396, 0.06315602,\n",
       "        0.0276808 , 0.12262704, 0.03474852, 0.14355634, 0.14011112]),\n",
       " 'param_C': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.1, 0.1, 0.25, 0.25, 0.5, 0.5, 1, 1, 5, 5, 0.1, 0.1,\n",
       "                    0.25, 0.25, 0.5, 0.5, 1, 1, 5, 5, 0.1, 0.1, 0.25, 0.25,\n",
       "                    0.5, 0.5, 1, 1, 5, 5, 0.1, 0.1, 0.25, 0.25, 0.5, 0.5,\n",
       "                    1, 1, 5, 5, 0.1, 0.1, 0.25, 0.25, 0.5, 0.5, 1, 1, 5, 5,\n",
       "                    0.1, 0.1, 0.25, 0.25, 0.5, 0.5, 1, 1, 5, 5, 0.1, 0.1,\n",
       "                    0.25, 0.25, 0.5, 0.5, 1, 1, 5, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 0.25, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.25, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 0.5, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'gamma': 5, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'gamma': 5, 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'gamma': 0.25, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.25, 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.5, 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'gamma': 5, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 5, 'kernel': 'linear'},\n",
       "  {'C': 0.5, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.5, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 0.5, 'gamma': 0.25, 'kernel': 'rbf'},\n",
       "  {'C': 0.5, 'gamma': 0.25, 'kernel': 'linear'},\n",
       "  {'C': 0.5, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "  {'C': 0.5, 'gamma': 0.5, 'kernel': 'linear'},\n",
       "  {'C': 0.5, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 0.5, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 0.5, 'gamma': 5, 'kernel': 'rbf'},\n",
       "  {'C': 0.5, 'gamma': 5, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.25, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.25, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.5, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 5, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 5, 'kernel': 'linear'},\n",
       "  {'C': 2, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 2, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 2, 'gamma': 0.25, 'kernel': 'rbf'},\n",
       "  {'C': 2, 'gamma': 0.25, 'kernel': 'linear'},\n",
       "  {'C': 2, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "  {'C': 2, 'gamma': 0.5, 'kernel': 'linear'},\n",
       "  {'C': 2, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 2, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 2, 'gamma': 5, 'kernel': 'rbf'},\n",
       "  {'C': 2, 'gamma': 5, 'kernel': 'linear'},\n",
       "  {'C': 5, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 5, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 5, 'gamma': 0.25, 'kernel': 'rbf'},\n",
       "  {'C': 5, 'gamma': 0.25, 'kernel': 'linear'},\n",
       "  {'C': 5, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "  {'C': 5, 'gamma': 0.5, 'kernel': 'linear'},\n",
       "  {'C': 5, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 5, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 5, 'gamma': 5, 'kernel': 'rbf'},\n",
       "  {'C': 5, 'gamma': 5, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.25, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.25, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.5, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 5, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 5, 'kernel': 'linear'}],\n",
       " 'split0_test_score': array([0.73673573, 0.80394138, 0.73673573, 0.80394138, 0.73673573,\n",
       "        0.80394138, 0.73673573, 0.80394138, 0.73673573, 0.80394138,\n",
       "        0.77968671, 0.80343608, 0.77362304, 0.80343608, 0.76402223,\n",
       "        0.80343608, 0.75442142, 0.80343608, 0.74077817, 0.80343608,\n",
       "        0.80192016, 0.80343608, 0.80242547, 0.80343608, 0.79484588,\n",
       "        0.80343608, 0.78322385, 0.80343608, 0.76250632, 0.80343608,\n",
       "        0.80242547, 0.80343608, 0.80394138, 0.80343608, 0.79939363,\n",
       "        0.80343608, 0.79181405, 0.80343608, 0.77311774, 0.80343608,\n",
       "        0.80646791, 0.80343608, 0.80040424, 0.80343608, 0.79737241,\n",
       "        0.80343608, 0.79434058, 0.80343608, 0.77311774, 0.80343608,\n",
       "        0.80949975, 0.80343608, 0.79787772, 0.80343608, 0.79231935,\n",
       "        0.80343608, 0.79383527, 0.80343608, 0.77311774, 0.80343608,\n",
       "        0.80242547, 0.80343608, 0.79181405, 0.80343608, 0.78928752,\n",
       "        0.80343608, 0.79383527, 0.80343608, 0.77311774, 0.80343608]),\n",
       " 'split1_test_score': array([0.73673573, 0.79383527, 0.73673573, 0.79383527, 0.73673573,\n",
       "        0.79383527, 0.73673573, 0.79383527, 0.73673573, 0.79383527,\n",
       "        0.77513896, 0.7968671 , 0.77564426, 0.7968671 , 0.76402223,\n",
       "        0.7968671 , 0.74987367, 0.7968671 , 0.73572511, 0.7968671 ,\n",
       "        0.7968671 , 0.7968671 , 0.79989894, 0.7968671 , 0.79585649,\n",
       "        0.7968671 , 0.7786761 , 0.7968671 , 0.7614957 , 0.7968671 ,\n",
       "        0.79888833, 0.7968671 , 0.79888833, 0.7968671 , 0.79080344,\n",
       "        0.7968671 , 0.78372916, 0.7968671 , 0.76452754, 0.7968671 ,\n",
       "        0.80293077, 0.7968671 , 0.79535119, 0.7968671 , 0.78827691,\n",
       "        0.7968671 , 0.7791814 , 0.7968671 , 0.76452754, 0.7968671 ,\n",
       "        0.80040424, 0.7968671 , 0.78575038, 0.7968671 , 0.77665488,\n",
       "        0.7968671 , 0.7791814 , 0.7968671 , 0.76452754, 0.7968671 ,\n",
       "        0.79484588, 0.7968671 , 0.78120263, 0.7968671 , 0.77261243,\n",
       "        0.7968671 , 0.77968671, 0.7968671 , 0.76452754, 0.7968671 ]),\n",
       " 'split2_test_score': array([0.73673573, 0.81556342, 0.73673573, 0.81556342, 0.73673573,\n",
       "        0.81556342, 0.73673573, 0.81556342, 0.73673573, 0.81556342,\n",
       "        0.7872663 , 0.81758464, 0.77564426, 0.81758464, 0.77059121,\n",
       "        0.81758464, 0.75543204, 0.81758464, 0.74279939, 0.81758464,\n",
       "        0.81202628, 0.81758464, 0.81354219, 0.81758464, 0.80596261,\n",
       "        0.81758464, 0.79535119, 0.81758464, 0.77665488, 0.81758464,\n",
       "        0.81556342, 0.81758464, 0.81707933, 0.81758464, 0.81202628,\n",
       "        0.81758464, 0.80242547, 0.81758464, 0.77968671, 0.81758464,\n",
       "        0.81808994, 0.81758464, 0.8145528 , 0.81758464, 0.81051036,\n",
       "        0.81758464, 0.80141486, 0.81758464, 0.77968671, 0.81758464,\n",
       "        0.81910056, 0.81758464, 0.80798383, 0.81758464, 0.79838302,\n",
       "        0.81758464, 0.79939363, 0.81758464, 0.77968671, 0.81758464,\n",
       "        0.81505811, 0.81758464, 0.80444669, 0.81758464, 0.79787772,\n",
       "        0.81758464, 0.79939363, 0.81758464, 0.77968671, 0.81758464]),\n",
       " 'split3_test_score': array([0.73673573, 0.79888833, 0.73673573, 0.79888833, 0.73673573,\n",
       "        0.79888833, 0.73673573, 0.79888833, 0.73673573, 0.79888833,\n",
       "        0.78928752, 0.80040424, 0.78019202, 0.80040424, 0.77160182,\n",
       "        0.80040424, 0.75138959, 0.80040424, 0.73875695, 0.80040424,\n",
       "        0.80848914, 0.80040424, 0.80646791, 0.80040424, 0.79282466,\n",
       "        0.80040424, 0.78372916, 0.80040424, 0.76200101, 0.80040424,\n",
       "        0.80899444, 0.80040424, 0.79888833, 0.80040424, 0.79332996,\n",
       "        0.80040424, 0.77210712, 0.80040424, 0.75846387, 0.80040424,\n",
       "        0.81354219, 0.80040424, 0.79888833, 0.80040424, 0.78676099,\n",
       "        0.80040424, 0.77210712, 0.80040424, 0.75846387, 0.80040424,\n",
       "        0.80596261, 0.80040424, 0.79080344, 0.80040424, 0.77412835,\n",
       "        0.80040424, 0.7700859 , 0.80040424, 0.75846387, 0.80040424,\n",
       "        0.79484588, 0.80040424, 0.78221324, 0.80040424, 0.76907529,\n",
       "        0.80040424, 0.7700859 , 0.80040424, 0.75846387, 0.80040424]),\n",
       " 'split4_test_score': array([0.73673573, 0.81960586, 0.73673573, 0.81960586, 0.73673573,\n",
       "        0.81960586, 0.73673573, 0.81960586, 0.73673573, 0.81960586,\n",
       "        0.78928752, 0.81859525, 0.78069732, 0.81859525, 0.77463365,\n",
       "        0.81859525, 0.75997979, 0.81859525, 0.7433047 , 0.81859525,\n",
       "        0.81051036, 0.81859525, 0.81253158, 0.81859525, 0.81101566,\n",
       "        0.81859525, 0.78928752, 0.81859525, 0.76856998, 0.81859525,\n",
       "        0.82011117, 0.81859525, 0.81758464, 0.81859525, 0.81758464,\n",
       "        0.81859525, 0.79737241, 0.81859525, 0.7786761 , 0.81859525,\n",
       "        0.82465892, 0.81859525, 0.81707933, 0.81859525, 0.80697322,\n",
       "        0.81859525, 0.79939363, 0.81859525, 0.7786761 , 0.81859525,\n",
       "        0.82061647, 0.81859525, 0.81707933, 0.81859525, 0.804952  ,\n",
       "        0.81859525, 0.79939363, 0.81859525, 0.7786761 , 0.81859525,\n",
       "        0.81960586, 0.81859525, 0.8140475 , 0.81859525, 0.7963618 ,\n",
       "        0.81859525, 0.79939363, 0.81859525, 0.7786761 , 0.81859525]),\n",
       " 'split5_test_score': array([0.73623042, 0.81303689, 0.73623042, 0.81303689, 0.73623042,\n",
       "        0.81303689, 0.73623042, 0.81303689, 0.73623042, 0.81303689,\n",
       "        0.7786761 , 0.81202628, 0.77261243, 0.81202628, 0.76604346,\n",
       "        0.81202628, 0.75088428, 0.81202628, 0.73825164, 0.81202628,\n",
       "        0.81253158, 0.81202628, 0.8140475 , 0.81202628, 0.804952  ,\n",
       "        0.81202628, 0.78928752, 0.81202628, 0.77109651, 0.81202628,\n",
       "        0.81910056, 0.81202628, 0.81303689, 0.81202628, 0.81101566,\n",
       "        0.81202628, 0.79383527, 0.81202628, 0.77210712, 0.81202628,\n",
       "        0.82061647, 0.81202628, 0.80697322, 0.81202628, 0.79939363,\n",
       "        0.81202628, 0.78575038, 0.81202628, 0.77210712, 0.81202628,\n",
       "        0.81606872, 0.81202628, 0.80242547, 0.81202628, 0.79282466,\n",
       "        0.81202628, 0.78271854, 0.81202628, 0.77210712, 0.81202628,\n",
       "        0.81354219, 0.81202628, 0.79130874, 0.81202628, 0.7877716 ,\n",
       "        0.81202628, 0.78271854, 0.81202628, 0.77210712, 0.81202628]),\n",
       " 'split6_test_score': array([0.73623042, 0.81707933, 0.73623042, 0.81707933, 0.73623042,\n",
       "        0.81707933, 0.73623042, 0.81707933, 0.73623042, 0.81707933,\n",
       "        0.78170793, 0.81910056, 0.77412835, 0.81910056, 0.76200101,\n",
       "        0.81910056, 0.74886306, 0.81910056, 0.73976756, 0.81910056,\n",
       "        0.80444669, 0.81910056, 0.79939363, 0.81910056, 0.79888833,\n",
       "        0.81910056, 0.7872663 , 0.81910056, 0.7695806 , 0.81910056,\n",
       "        0.80596261, 0.81910056, 0.80798383, 0.81910056, 0.79838302,\n",
       "        0.81910056, 0.79231935, 0.81910056, 0.77513896, 0.81910056,\n",
       "        0.8054573 , 0.81910056, 0.80040424, 0.81910056, 0.79484588,\n",
       "        0.81910056, 0.7877716 , 0.81910056, 0.77513896, 0.81910056,\n",
       "        0.80596261, 0.81910056, 0.79737241, 0.81910056, 0.79383527,\n",
       "        0.81910056, 0.78524507, 0.81910056, 0.77513896, 0.81910056,\n",
       "        0.80343608, 0.81910056, 0.79231935, 0.81910056, 0.78878221,\n",
       "        0.81910056, 0.78575038, 0.81910056, 0.77513896, 0.81910056]),\n",
       " 'split7_test_score': array([0.73660263, 0.81395349, 0.73660263, 0.81395349, 0.73660263,\n",
       "        0.81395349, 0.73660263, 0.81395349, 0.73660263, 0.81395349,\n",
       "        0.79575329, 0.81496461, 0.78463094, 0.81496461, 0.77906977,\n",
       "        0.81496461, 0.760364  , 0.81496461, 0.74165824, 0.81496461,\n",
       "        0.81344793, 0.81496461, 0.81496461, 0.81496461, 0.81142568,\n",
       "        0.81496461, 0.79828109, 0.81496461, 0.77553084, 0.81496461,\n",
       "        0.81799798, 0.81496461, 0.81344793, 0.81496461, 0.81294237,\n",
       "        0.81496461, 0.80182002, 0.81496461, 0.78058645, 0.81496461,\n",
       "        0.82204247, 0.81496461, 0.81395349, 0.81496461, 0.81092012,\n",
       "        0.81496461, 0.7942366 , 0.81496461, 0.78058645, 0.81496461,\n",
       "        0.8190091 , 0.81496461, 0.81597573, 0.81496461, 0.80485339,\n",
       "        0.81496461, 0.79373104, 0.81496461, 0.78058645, 0.81496461,\n",
       "        0.81951466, 0.81496461, 0.81294237, 0.81496461, 0.79929221,\n",
       "        0.81496461, 0.79373104, 0.81496461, 0.78058645, 0.81496461]),\n",
       " 'split8_test_score': array([0.73660263, 0.81041456, 0.73660263, 0.81041456, 0.73660263,\n",
       "        0.81041456, 0.73660263, 0.81041456, 0.73660263, 0.81041456,\n",
       "        0.78210313, 0.8124368 , 0.77805865, 0.8124368 , 0.76541962,\n",
       "        0.8124368 , 0.75025278, 0.8124368 , 0.739636  , 0.8124368 ,\n",
       "        0.81597573, 0.8124368 , 0.8124368 , 0.8124368 , 0.80131446,\n",
       "        0.8124368 , 0.7851365 , 0.8124368 , 0.7669363 , 0.8124368 ,\n",
       "        0.81951466, 0.8124368 , 0.81850354, 0.8124368 , 0.80283114,\n",
       "        0.8124368 , 0.79019211, 0.8124368 , 0.76592518, 0.8124368 ,\n",
       "        0.81850354, 0.8124368 , 0.81092012, 0.8124368 , 0.80182002,\n",
       "        0.8124368 , 0.78159757, 0.8124368 , 0.76592518, 0.8124368 ,\n",
       "        0.81547017, 0.8124368 , 0.80586451, 0.8124368 , 0.78816987,\n",
       "        0.8124368 , 0.78109201, 0.8124368 , 0.76592518, 0.8124368 ,\n",
       "        0.81445905, 0.8124368 , 0.79221436, 0.8124368 , 0.77654196,\n",
       "        0.8124368 , 0.78109201, 0.8124368 , 0.76592518, 0.8124368 ]),\n",
       " 'split9_test_score': array([0.73660263, 0.80283114, 0.73660263, 0.80283114, 0.73660263,\n",
       "        0.80283114, 0.73660263, 0.80283114, 0.73660263, 0.80283114,\n",
       "        0.77451972, 0.8033367 , 0.77350859, 0.8033367 , 0.76744186,\n",
       "        0.8033367 , 0.75025278, 0.8033367 , 0.74165824, 0.8033367 ,\n",
       "        0.79777553, 0.8033367 , 0.79929221, 0.8033367 , 0.79474216,\n",
       "        0.8033367 , 0.78159757, 0.8033367 , 0.76137513, 0.8033367 ,\n",
       "        0.80839232, 0.8033367 , 0.80839232, 0.8033367 , 0.79777553,\n",
       "        0.8033367 , 0.78715875, 0.8033367 , 0.76845298, 0.8033367 ,\n",
       "        0.81142568, 0.8033367 , 0.80889788, 0.8033367 , 0.79929221,\n",
       "        0.8033367 , 0.78665319, 0.8033367 , 0.76845298, 0.8033367 ,\n",
       "        0.80889788, 0.8033367 , 0.79979778, 0.8033367 , 0.79221436,\n",
       "        0.8033367 , 0.78766431, 0.8033367 , 0.76845298, 0.8033367 ,\n",
       "        0.80637007, 0.8033367 , 0.79777553, 0.8033367 , 0.78918099,\n",
       "        0.8033367 , 0.78766431, 0.8033367 , 0.76845298, 0.8033367 ]),\n",
       " 'mean_test_score': array([0.73659474, 0.80891497, 0.73659474, 0.80891497, 0.73659474,\n",
       "        0.80891497, 0.73659474, 0.80891497, 0.73659474, 0.80891497,\n",
       "        0.78334272, 0.80987523, 0.77687399, 0.80987523, 0.76848469,\n",
       "        0.80987523, 0.75317134, 0.80987523, 0.7402336 , 0.80987523,\n",
       "        0.80739905, 0.80987523, 0.80750009, 0.80987523, 0.80118279,\n",
       "        0.80987523, 0.78718368, 0.80987523, 0.76757473, 0.80987523,\n",
       "        0.81169509, 0.80987523, 0.80977465, 0.80987523, 0.80360857,\n",
       "        0.80987523, 0.79127737, 0.80987523, 0.77166827, 0.80987523,\n",
       "        0.81437352, 0.80987523, 0.80674248, 0.80987523, 0.79961658,\n",
       "        0.80987523, 0.78824469, 0.80987523, 0.77166827, 0.80987523,\n",
       "        0.81209921, 0.80987523, 0.80209306, 0.80987523, 0.79183351,\n",
       "        0.80987523, 0.78723408, 0.80987523, 0.77166827, 0.80987523,\n",
       "        0.80841033, 0.80987523, 0.79602845, 0.80987523, 0.78667837,\n",
       "        0.80987523, 0.78733514, 0.80987523, 0.77166827, 0.80987523]),\n",
       " 'std_test_score': array([0.00019106, 0.00812071, 0.00019106, 0.00812071, 0.00019106,\n",
       "        0.00812071, 0.00019106, 0.00812071, 0.00019106, 0.00812071,\n",
       "        0.00651612, 0.00775111, 0.0037124 , 0.00775111, 0.00512166,\n",
       "        0.00775111, 0.0039955 , 0.00775111, 0.0021767 , 0.00775111,\n",
       "        0.00641124, 0.00775111, 0.00634398, 0.00775111, 0.00651002,\n",
       "        0.00775111, 0.00578021, 0.00775111, 0.005438  , 0.00775111,\n",
       "        0.00736552, 0.00775111, 0.00700608, 0.00775111, 0.00870342,\n",
       "        0.00775111, 0.00850358, 0.00775111, 0.00689888, 0.00775111,\n",
       "        0.0071886 , 0.00775111, 0.00716797, 0.00775111, 0.00791975,\n",
       "        0.00775111, 0.00875524, 0.00775111, 0.00689888, 0.00775111,\n",
       "        0.00652322, 0.00775111, 0.00951952, 0.00775111, 0.00973224,\n",
       "        0.00775111, 0.00895912, 0.00775111, 0.00689888, 0.00775111,\n",
       "        0.00887961, 0.00775111, 0.01078746, 0.00775111, 0.01003724,\n",
       "        0.00775111, 0.00890459, 0.00775111, 0.00689888, 0.00775111]),\n",
       " 'rank_test_score': array([66, 35, 66, 35, 66, 35, 66, 35, 66, 35, 56,  4, 57,  4, 62,  4, 64,\n",
       "         4, 65,  4, 42,  4, 41,  4, 46,  4, 54,  4, 63,  4,  3,  4, 34,  4,\n",
       "        44,  4, 50,  4, 58,  4,  1,  4, 43,  4, 47,  4, 51,  4, 58,  4,  2,\n",
       "         4, 45,  4, 49,  4, 53,  4, 58,  4, 40,  4, 48,  4, 55,  4, 52,  4,\n",
       "        58,  4]),\n",
       " 'split0_train_score': array([0.73657907, 0.80969227, 0.73657907, 0.80969227, 0.73657907,\n",
       "        0.80969227, 0.73657907, 0.80969227, 0.73657907, 0.80969227,\n",
       "        0.79009434, 0.81059075, 0.78694969, 0.81059075, 0.77723495,\n",
       "        0.81059075, 0.75977089, 0.81059075, 0.74275606, 0.81059075,\n",
       "        0.82249551, 0.81059075, 0.83361411, 0.81059075, 0.83894879,\n",
       "        0.81059075, 0.83445642, 0.81059075, 0.80362758, 0.81059075,\n",
       "        0.83209793, 0.81059075, 0.85298742, 0.81059075, 0.87432615,\n",
       "        0.81059075, 0.89549641, 0.81059075, 0.90408805, 0.81059075,\n",
       "        0.84428347, 0.81059075, 0.86798068, 0.81059075, 0.89100404,\n",
       "        0.81059075, 0.9035265 , 0.81059075, 0.90408805, 0.81059075,\n",
       "        0.85686208, 0.81059075, 0.88387242, 0.81059075, 0.90010108,\n",
       "        0.81059075, 0.90408805, 0.81059075, 0.90408805, 0.81059075,\n",
       "        0.86506065, 0.81059075, 0.89179021, 0.81059075, 0.90307727,\n",
       "        0.81059075, 0.90408805, 0.81059075, 0.90408805, 0.81059075]),\n",
       " 'split1_train_score': array([0.73657907, 0.81047844, 0.73657907, 0.81047844, 0.73657907,\n",
       "        0.81047844, 0.73657907, 0.81047844, 0.73657907, 0.81047844,\n",
       "        0.79278976, 0.81132075, 0.78885894, 0.81132075, 0.77936882,\n",
       "        0.81132075, 0.7611186 , 0.81132075, 0.74286837, 0.81132075,\n",
       "        0.82137242, 0.81132075, 0.83479335, 0.81132075, 0.84192498,\n",
       "        0.81132075, 0.83715184, 0.81132075, 0.8057053 , 0.81132075,\n",
       "        0.83221024, 0.81132075, 0.85315588, 0.81132075, 0.87707772,\n",
       "        0.81132075, 0.89830413, 0.81132075, 0.90571653, 0.81132075,\n",
       "        0.84327269, 0.81132075, 0.87039533, 0.81132075, 0.89347484,\n",
       "        0.81132075, 0.90504268, 0.81132075, 0.90571653, 0.81132075,\n",
       "        0.85916442, 0.81132075, 0.88606244, 0.81132075, 0.90184187,\n",
       "        0.81132075, 0.90571653, 0.81132075, 0.90571653, 0.81132075,\n",
       "        0.86725067, 0.81132075, 0.89336253, 0.81132075, 0.90487421,\n",
       "        0.81132075, 0.90571653, 0.81132075, 0.90571653, 0.81132075]),\n",
       " 'split2_train_score': array([0.73657907, 0.8087938 , 0.73657907, 0.8087938 , 0.73657907,\n",
       "        0.8087938 , 0.73657907, 0.8087938 , 0.73657907, 0.8087938 ,\n",
       "        0.78986972, 0.80901842, 0.78919587, 0.80901842, 0.77818958,\n",
       "        0.80901842, 0.75859164, 0.80901842, 0.74202606, 0.80901842,\n",
       "        0.82204627, 0.80901842, 0.83372642, 0.80901842, 0.8384434 ,\n",
       "        0.80901842, 0.83299641, 0.80901842, 0.80390836, 0.80901842,\n",
       "        0.83176101, 0.80901842, 0.85265049, 0.80901842, 0.87342767,\n",
       "        0.80901842, 0.89499102, 0.80901842, 0.90380728, 0.80901842,\n",
       "        0.84203729, 0.80901842, 0.86854223, 0.80901842, 0.89033019,\n",
       "        0.80901842, 0.90307727, 0.80901842, 0.90380728, 0.80901842,\n",
       "        0.85674978, 0.80901842, 0.88347934, 0.80901842, 0.89965184,\n",
       "        0.80901842, 0.90380728, 0.80901842, 0.90380728, 0.80901842,\n",
       "        0.86517296, 0.80901842, 0.89128482, 0.80901842, 0.90257188,\n",
       "        0.80901842, 0.90380728, 0.80901842, 0.90380728, 0.80901842]),\n",
       " 'split3_train_score': array([0.73657907, 0.81036613, 0.73657907, 0.81036613, 0.73657907,\n",
       "        0.81036613, 0.73657907, 0.81036613, 0.73657907, 0.81036613,\n",
       "        0.79093666, 0.81092767, 0.78666891, 0.81092767, 0.77818958,\n",
       "        0.81092767, 0.76005166, 0.81092767, 0.7425876 , 0.81092767,\n",
       "        0.82373091, 0.81092767, 0.83529874, 0.81092767, 0.84237421,\n",
       "        0.81092767, 0.83557951, 0.81092767, 0.80727763, 0.81092767,\n",
       "        0.83361411, 0.81092767, 0.8552336 , 0.81092767, 0.87578616,\n",
       "        0.81092767, 0.8978549 , 0.81092767, 0.90571653, 0.81092767,\n",
       "        0.8434973 , 0.81092767, 0.87140611, 0.81092767, 0.89190252,\n",
       "        0.81092767, 0.90504268, 0.81092767, 0.90571653, 0.81092767,\n",
       "        0.85966981, 0.81092767, 0.88409704, 0.81092767, 0.90111186,\n",
       "        0.81092767, 0.90571653, 0.81092767, 0.90571653, 0.81092767,\n",
       "        0.86736298, 0.81092767, 0.89207098, 0.81092767, 0.90487421,\n",
       "        0.81092767, 0.90571653, 0.81092767, 0.90571653, 0.81092767]),\n",
       " 'split4_train_score': array([0.73657907, 0.80851303, 0.73657907, 0.80851303, 0.73657907,\n",
       "        0.80851303, 0.73657907, 0.80851303, 0.73657907, 0.80851303,\n",
       "        0.79082435, 0.80890611, 0.78728661, 0.80890611, 0.7785265 ,\n",
       "        0.80890611, 0.75982704, 0.80890611, 0.74303684, 0.80890611,\n",
       "        0.81968778, 0.80890611, 0.83181716, 0.80890611, 0.83821878,\n",
       "        0.80890611, 0.83221024, 0.80890611, 0.80317835, 0.80890611,\n",
       "        0.83063792, 0.80890611, 0.85141509, 0.80890611, 0.87387691,\n",
       "        0.80890611, 0.8953841 , 0.80890611, 0.90358266, 0.80890611,\n",
       "        0.84130728, 0.80890611, 0.86747529, 0.80890611, 0.88954403,\n",
       "        0.80890611, 0.90268419, 0.80890611, 0.90358266, 0.80890611,\n",
       "        0.85618823, 0.80890611, 0.88274933, 0.80890611, 0.89925876,\n",
       "        0.80890611, 0.90358266, 0.80890611, 0.90358266, 0.80890611,\n",
       "        0.86595912, 0.80890611, 0.89027403, 0.80890611, 0.90245957,\n",
       "        0.80890611, 0.90358266, 0.80890611, 0.90358266, 0.80890611]),\n",
       " 'split5_train_score': array([0.73663522, 0.80851303, 0.73663522, 0.80851303, 0.73663522,\n",
       "        0.80851303, 0.73663522, 0.80851303, 0.73663522, 0.80851303,\n",
       "        0.7896451 , 0.80963612, 0.78582659, 0.80963612, 0.77751572,\n",
       "        0.80963612, 0.76055705, 0.80963612, 0.7419699 , 0.80963612,\n",
       "        0.82019317, 0.80963612, 0.83159254, 0.80963612, 0.8402965 ,\n",
       "        0.80963612, 0.83338949, 0.80963612, 0.80463836, 0.80963612,\n",
       "        0.83080638, 0.80963612, 0.85304358, 0.80963612, 0.87404537,\n",
       "        0.80963612, 0.89532794, 0.80963612, 0.90380728, 0.80963612,\n",
       "        0.84248652, 0.80963612, 0.86803684, 0.80963612, 0.89072327,\n",
       "        0.80963612, 0.90296496, 0.80963612, 0.90380728, 0.80963612,\n",
       "        0.85674978, 0.80963612, 0.88387242, 0.80963612, 0.8990903 ,\n",
       "        0.80963612, 0.90380728, 0.80963612, 0.90380728, 0.80963612,\n",
       "        0.8644991 , 0.80963612, 0.89128482, 0.80963612, 0.9027965 ,\n",
       "        0.80963612, 0.90380728, 0.80963612, 0.90380728, 0.80963612]),\n",
       " 'split6_train_score': array([0.73663522, 0.80823226, 0.73663522, 0.80823226, 0.73663522,\n",
       "        0.80823226, 0.73663522, 0.80823226, 0.73663522, 0.80823226,\n",
       "        0.79132974, 0.80884996, 0.78919587, 0.80884996, 0.77785265,\n",
       "        0.80884996, 0.76139937, 0.80884996, 0.74410377, 0.80884996,\n",
       "        0.82249551, 0.80884996, 0.83338949, 0.80884996, 0.84052111,\n",
       "        0.80884996, 0.83395103, 0.80884996, 0.80418913, 0.80884996,\n",
       "        0.83209793, 0.80884996, 0.85287511, 0.80884996, 0.87415768,\n",
       "        0.80884996, 0.89544025, 0.80884996, 0.90380728, 0.80884996,\n",
       "        0.84327269, 0.80884996, 0.8682053 , 0.80884996, 0.88971249,\n",
       "        0.80884996, 0.90313342, 0.80884996, 0.90380728, 0.80884996,\n",
       "        0.85742363, 0.80884996, 0.88314241, 0.80884996, 0.899708  ,\n",
       "        0.80884996, 0.90380728, 0.80884996, 0.90380728, 0.80884996,\n",
       "        0.8651168 , 0.80884996, 0.89038634, 0.80884996, 0.9027965 ,\n",
       "        0.80884996, 0.90380728, 0.80884996, 0.90380728, 0.80884996]),\n",
       " 'split7_train_score': array([0.73659386, 0.80857993, 0.73659386, 0.80857993, 0.73659386,\n",
       "        0.80857993, 0.73659386, 0.80857993, 0.73659386, 0.80857993,\n",
       "        0.79038688, 0.8093099 , 0.78808468, 0.8093099 , 0.77814588,\n",
       "        0.8093099 , 0.75714526, 0.8093099 , 0.74102982, 0.8093099 ,\n",
       "        0.82138245, 0.8093099 , 0.8337919 , 0.8093099 , 0.83895783,\n",
       "        0.8093099 , 0.83289348, 0.8093099 , 0.80217867, 0.8093099 ,\n",
       "        0.8318266 , 0.8093099 , 0.85277107, 0.8093099 , 0.87394014,\n",
       "        0.8093099 , 0.89572688, 0.8093099 , 0.90414959, 0.8093099 ,\n",
       "        0.84288843, 0.8093099 , 0.86720198, 0.8093099 , 0.88977483,\n",
       "        0.8093099 , 0.90302656, 0.8093099 , 0.90414959, 0.8093099 ,\n",
       "        0.85698242, 0.8093099 , 0.882419  , 0.8093099 , 0.90021899,\n",
       "        0.8093099 , 0.90414959, 0.8093099 , 0.90414959, 0.8093099 ,\n",
       "        0.86461901, 0.8093099 , 0.88988714, 0.8093099 , 0.90302656,\n",
       "        0.8093099 , 0.90414959, 0.8093099 , 0.90414959, 0.8093099 ]),\n",
       " 'split8_train_score': array([0.73659386, 0.80869223, 0.73659386, 0.80869223, 0.73659386,\n",
       "        0.80869223, 0.73659386, 0.80869223, 0.73659386, 0.80869223,\n",
       "        0.79072379, 0.80959066, 0.78673704, 0.80959066, 0.778932  ,\n",
       "        0.80959066, 0.75989668, 0.80959066, 0.74423045, 0.80959066,\n",
       "        0.82031557, 0.80959066, 0.83339884, 0.80959066, 0.83918244,\n",
       "        0.80959066, 0.83407266, 0.80959066, 0.803414  , 0.80959066,\n",
       "        0.83053512, 0.80959066, 0.85338874, 0.80959066, 0.87517547,\n",
       "        0.80959066, 0.89668145, 0.80959066, 0.90532877, 0.80959066,\n",
       "        0.84300073, 0.80959066, 0.86860576, 0.80959066, 0.89078556,\n",
       "        0.80959066, 0.90437419, 0.80959066, 0.90532877, 0.80959066,\n",
       "        0.857937  , 0.80959066, 0.88275591, 0.80959066, 0.90089281,\n",
       "        0.80959066, 0.90532877, 0.80959066, 0.90532877, 0.80959066,\n",
       "        0.86591049, 0.80959066, 0.8925824 , 0.80959066, 0.90409344,\n",
       "        0.80959066, 0.90532877, 0.80959066, 0.90532877, 0.80959066]),\n",
       " 'split9_train_score': array([0.73659386, 0.80959066, 0.73659386, 0.80959066, 0.73659386,\n",
       "        0.80959066, 0.73659386, 0.80959066, 0.73659386, 0.80959066,\n",
       "        0.7909484 , 0.81060138, 0.7871301 , 0.81060138, 0.77837049,\n",
       "        0.81060138, 0.75995283, 0.81060138, 0.74400584, 0.81060138,\n",
       "        0.82076478, 0.81060138, 0.83244427, 0.81060138, 0.83828401,\n",
       "        0.81060138, 0.83440957, 0.81060138, 0.80493009, 0.81060138,\n",
       "        0.83126509, 0.81060138, 0.85215341, 0.81060138, 0.87298557,\n",
       "        0.81060138, 0.89527767, 0.81060138, 0.90353192, 0.81060138,\n",
       "        0.84277612, 0.81060138, 0.86793194, 0.81060138, 0.88994329,\n",
       "        0.81060138, 0.90280195, 0.81060138, 0.90353192, 0.81060138,\n",
       "        0.85591555, 0.81060138, 0.88309282, 0.81060138, 0.89937672,\n",
       "        0.81060138, 0.90353192, 0.81060138, 0.90353192, 0.81060138,\n",
       "        0.86478747, 0.81060138, 0.89016789, 0.81060138, 0.90268965,\n",
       "        0.81060138, 0.90353192, 0.81060138, 0.90353192, 0.81060138]),\n",
       " 'mean_train_score': array([0.73659473, 0.80914518, 0.73659473, 0.80914518, 0.73659473,\n",
       "        0.80914518, 0.73659473, 0.80914518, 0.73659473, 0.80914518,\n",
       "        0.79075487, 0.80987517, 0.78759343, 0.80987517, 0.77823262,\n",
       "        0.80987517, 0.7598311 , 0.80987517, 0.74286147, 0.80987517,\n",
       "        0.82144844, 0.80987517, 0.83338668, 0.80987517, 0.8397152 ,\n",
       "        0.80987517, 0.83411107, 0.80987517, 0.80430475, 0.80987517,\n",
       "        0.83168523, 0.80987517, 0.85296744, 0.80987517, 0.87447988,\n",
       "        0.80987517, 0.89604847, 0.80987517, 0.90435359, 0.80987517,\n",
       "        0.84288225, 0.80987517, 0.86857815, 0.80987517, 0.89071951,\n",
       "        0.80987517, 0.90356744, 0.80987517, 0.90435359, 0.80987517,\n",
       "        0.85736427, 0.80987517, 0.88355431, 0.80987517, 0.90012522,\n",
       "        0.80987517, 0.90435359, 0.80987517, 0.90435359, 0.80987517,\n",
       "        0.86557393, 0.80987517, 0.89130912, 0.80987517, 0.90332598,\n",
       "        0.80987517, 0.90435359, 0.80987517, 0.90435359, 0.80987517]),\n",
       " 'std_train_score': array([2.12321820e-05, 7.77614565e-04, 2.12321820e-05, 7.77614565e-04,\n",
       "        2.12321820e-05, 7.77614565e-04, 2.12321820e-05, 7.77614565e-04,\n",
       "        2.12321820e-05, 7.77614565e-04, 8.44648981e-04, 8.61318753e-04,\n",
       "        1.11406911e-03, 8.61318753e-04, 5.95848731e-04, 8.61318753e-04,\n",
       "        1.16040988e-03, 8.61318753e-04, 9.84463126e-04, 8.61318753e-04,\n",
       "        1.19148213e-03, 8.61318753e-04, 1.11967254e-03, 8.61318753e-04,\n",
       "        1.42445663e-03, 8.61318753e-04, 1.36003331e-03, 8.61318753e-04,\n",
       "        1.36063816e-03, 8.61318753e-04, 8.79266077e-04, 8.61318753e-04,\n",
       "        9.25994654e-04, 8.61318753e-04, 1.15109623e-03, 8.61318753e-04,\n",
       "        1.10466654e-03, 8.61318753e-04, 8.33256399e-04, 8.61318753e-04,\n",
       "        7.76081494e-04, 8.61318753e-04, 1.24973107e-03, 8.61318753e-04,\n",
       "        1.14538469e-03, 8.61318753e-04, 8.63449736e-04, 8.61318753e-04,\n",
       "        8.33256399e-04, 8.61318753e-04, 1.16287023e-03, 8.61318753e-04,\n",
       "        9.87435863e-04, 8.61318753e-04, 8.54350131e-04, 8.61318753e-04,\n",
       "        8.33256399e-04, 8.61318753e-04, 8.33256399e-04, 8.61318753e-04,\n",
       "        9.79422296e-04, 8.61318753e-04, 1.09078731e-03, 8.61318753e-04,\n",
       "        8.84280160e-04, 8.61318753e-04, 8.33256399e-04, 8.61318753e-04,\n",
       "        8.33256399e-04, 8.61318753e-04])}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covert the results in data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result_svc=pd.DataFrame.from_dict(svc_grid_fit.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.706019</td>\n",
       "      <td>1.619968</td>\n",
       "      <td>1.969547</td>\n",
       "      <td>0.201109</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.736736</td>\n",
       "      <td>0.736736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736579</td>\n",
       "      <td>0.736579</td>\n",
       "      <td>0.736579</td>\n",
       "      <td>0.736635</td>\n",
       "      <td>0.736635</td>\n",
       "      <td>0.736594</td>\n",
       "      <td>0.736594</td>\n",
       "      <td>0.736594</td>\n",
       "      <td>0.736595</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.579594</td>\n",
       "      <td>1.390514</td>\n",
       "      <td>1.186453</td>\n",
       "      <td>0.085674</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>0.803941</td>\n",
       "      <td>0.793835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808794</td>\n",
       "      <td>0.810366</td>\n",
       "      <td>0.808513</td>\n",
       "      <td>0.808513</td>\n",
       "      <td>0.808232</td>\n",
       "      <td>0.808580</td>\n",
       "      <td>0.808692</td>\n",
       "      <td>0.809591</td>\n",
       "      <td>0.809145</td>\n",
       "      <td>0.000778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.057631</td>\n",
       "      <td>2.157766</td>\n",
       "      <td>2.423865</td>\n",
       "      <td>0.406386</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.25, 'kernel': 'rbf'}</td>\n",
       "      <td>0.736736</td>\n",
       "      <td>0.736736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736579</td>\n",
       "      <td>0.736579</td>\n",
       "      <td>0.736579</td>\n",
       "      <td>0.736635</td>\n",
       "      <td>0.736635</td>\n",
       "      <td>0.736594</td>\n",
       "      <td>0.736594</td>\n",
       "      <td>0.736594</td>\n",
       "      <td>0.736595</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.584368</td>\n",
       "      <td>4.628833</td>\n",
       "      <td>1.412633</td>\n",
       "      <td>0.367932</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.25, 'kernel': 'linear'}</td>\n",
       "      <td>0.803941</td>\n",
       "      <td>0.793835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808794</td>\n",
       "      <td>0.810366</td>\n",
       "      <td>0.808513</td>\n",
       "      <td>0.808513</td>\n",
       "      <td>0.808232</td>\n",
       "      <td>0.808580</td>\n",
       "      <td>0.808692</td>\n",
       "      <td>0.809591</td>\n",
       "      <td>0.809145</td>\n",
       "      <td>0.000778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.382801</td>\n",
       "      <td>8.022057</td>\n",
       "      <td>3.133083</td>\n",
       "      <td>0.934870</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.5, 'kernel': 'rbf'}</td>\n",
       "      <td>0.736736</td>\n",
       "      <td>0.736736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736579</td>\n",
       "      <td>0.736579</td>\n",
       "      <td>0.736579</td>\n",
       "      <td>0.736635</td>\n",
       "      <td>0.736635</td>\n",
       "      <td>0.736594</td>\n",
       "      <td>0.736594</td>\n",
       "      <td>0.736594</td>\n",
       "      <td>0.736595</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>643.097507</td>\n",
       "      <td>17.460349</td>\n",
       "      <td>0.596212</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'gamma': 0.5, 'kernel': 'linear'}</td>\n",
       "      <td>0.803436</td>\n",
       "      <td>0.796867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809018</td>\n",
       "      <td>0.810928</td>\n",
       "      <td>0.808906</td>\n",
       "      <td>0.809636</td>\n",
       "      <td>0.808850</td>\n",
       "      <td>0.809310</td>\n",
       "      <td>0.809591</td>\n",
       "      <td>0.810601</td>\n",
       "      <td>0.809875</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>98.033350</td>\n",
       "      <td>4.721209</td>\n",
       "      <td>2.535846</td>\n",
       "      <td>0.122627</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.793835</td>\n",
       "      <td>0.779687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903807</td>\n",
       "      <td>0.905717</td>\n",
       "      <td>0.903583</td>\n",
       "      <td>0.903807</td>\n",
       "      <td>0.903807</td>\n",
       "      <td>0.904150</td>\n",
       "      <td>0.905329</td>\n",
       "      <td>0.903532</td>\n",
       "      <td>0.904354</td>\n",
       "      <td>0.000833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>654.046519</td>\n",
       "      <td>26.045299</td>\n",
       "      <td>0.593763</td>\n",
       "      <td>0.034749</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.803436</td>\n",
       "      <td>0.796867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809018</td>\n",
       "      <td>0.810928</td>\n",
       "      <td>0.808906</td>\n",
       "      <td>0.809636</td>\n",
       "      <td>0.808850</td>\n",
       "      <td>0.809310</td>\n",
       "      <td>0.809591</td>\n",
       "      <td>0.810601</td>\n",
       "      <td>0.809875</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>131.024122</td>\n",
       "      <td>10.375285</td>\n",
       "      <td>3.702564</td>\n",
       "      <td>0.143556</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 5, 'kernel': 'rbf'}</td>\n",
       "      <td>0.773118</td>\n",
       "      <td>0.764528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903807</td>\n",
       "      <td>0.905717</td>\n",
       "      <td>0.903583</td>\n",
       "      <td>0.903807</td>\n",
       "      <td>0.903807</td>\n",
       "      <td>0.904150</td>\n",
       "      <td>0.905329</td>\n",
       "      <td>0.903532</td>\n",
       "      <td>0.904354</td>\n",
       "      <td>0.000833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>639.168699</td>\n",
       "      <td>94.895848</td>\n",
       "      <td>0.522562</td>\n",
       "      <td>0.140111</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'gamma': 5, 'kernel': 'linear'}</td>\n",
       "      <td>0.803436</td>\n",
       "      <td>0.796867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809018</td>\n",
       "      <td>0.810928</td>\n",
       "      <td>0.808906</td>\n",
       "      <td>0.809636</td>\n",
       "      <td>0.808850</td>\n",
       "      <td>0.809310</td>\n",
       "      <td>0.809591</td>\n",
       "      <td>0.810601</td>\n",
       "      <td>0.809875</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       41.706019      1.619968         1.969547        0.201109    0.01   \n",
       "1       37.579594      1.390514         1.186453        0.085674    0.01   \n",
       "2       40.057631      2.157766         2.423865        0.406386    0.01   \n",
       "3       38.584368      4.628833         1.412633        0.367932    0.01   \n",
       "4       57.382801      8.022057         3.133083        0.934870    0.01   \n",
       "..            ...           ...              ...             ...     ...   \n",
       "65     643.097507     17.460349         0.596212        0.027681      10   \n",
       "66      98.033350      4.721209         2.535846        0.122627      10   \n",
       "67     654.046519     26.045299         0.593763        0.034749      10   \n",
       "68     131.024122     10.375285         3.702564        0.143556      10   \n",
       "69     639.168699     94.895848         0.522562        0.140111      10   \n",
       "\n",
       "   param_gamma param_kernel                                          params  \\\n",
       "0          0.1          rbf      {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "1          0.1       linear   {'C': 0.01, 'gamma': 0.1, 'kernel': 'linear'}   \n",
       "2         0.25          rbf     {'C': 0.01, 'gamma': 0.25, 'kernel': 'rbf'}   \n",
       "3         0.25       linear  {'C': 0.01, 'gamma': 0.25, 'kernel': 'linear'}   \n",
       "4          0.5          rbf      {'C': 0.01, 'gamma': 0.5, 'kernel': 'rbf'}   \n",
       "..         ...          ...                                             ...   \n",
       "65         0.5       linear     {'C': 10, 'gamma': 0.5, 'kernel': 'linear'}   \n",
       "66           1          rbf          {'C': 10, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "67           1       linear       {'C': 10, 'gamma': 1, 'kernel': 'linear'}   \n",
       "68           5          rbf          {'C': 10, 'gamma': 5, 'kernel': 'rbf'}   \n",
       "69           5       linear       {'C': 10, 'gamma': 5, 'kernel': 'linear'}   \n",
       "\n",
       "    split0_test_score  split1_test_score  ...  split2_train_score  \\\n",
       "0            0.736736           0.736736  ...            0.736579   \n",
       "1            0.803941           0.793835  ...            0.808794   \n",
       "2            0.736736           0.736736  ...            0.736579   \n",
       "3            0.803941           0.793835  ...            0.808794   \n",
       "4            0.736736           0.736736  ...            0.736579   \n",
       "..                ...                ...  ...                 ...   \n",
       "65           0.803436           0.796867  ...            0.809018   \n",
       "66           0.793835           0.779687  ...            0.903807   \n",
       "67           0.803436           0.796867  ...            0.809018   \n",
       "68           0.773118           0.764528  ...            0.903807   \n",
       "69           0.803436           0.796867  ...            0.809018   \n",
       "\n",
       "    split3_train_score  split4_train_score  split5_train_score  \\\n",
       "0             0.736579            0.736579            0.736635   \n",
       "1             0.810366            0.808513            0.808513   \n",
       "2             0.736579            0.736579            0.736635   \n",
       "3             0.810366            0.808513            0.808513   \n",
       "4             0.736579            0.736579            0.736635   \n",
       "..                 ...                 ...                 ...   \n",
       "65            0.810928            0.808906            0.809636   \n",
       "66            0.905717            0.903583            0.903807   \n",
       "67            0.810928            0.808906            0.809636   \n",
       "68            0.905717            0.903583            0.903807   \n",
       "69            0.810928            0.808906            0.809636   \n",
       "\n",
       "    split6_train_score  split7_train_score  split8_train_score  \\\n",
       "0             0.736635            0.736594            0.736594   \n",
       "1             0.808232            0.808580            0.808692   \n",
       "2             0.736635            0.736594            0.736594   \n",
       "3             0.808232            0.808580            0.808692   \n",
       "4             0.736635            0.736594            0.736594   \n",
       "..                 ...                 ...                 ...   \n",
       "65            0.808850            0.809310            0.809591   \n",
       "66            0.903807            0.904150            0.905329   \n",
       "67            0.808850            0.809310            0.809591   \n",
       "68            0.903807            0.904150            0.905329   \n",
       "69            0.808850            0.809310            0.809591   \n",
       "\n",
       "    split9_train_score  mean_train_score  std_train_score  \n",
       "0             0.736594          0.736595         0.000021  \n",
       "1             0.809591          0.809145         0.000778  \n",
       "2             0.736594          0.736595         0.000021  \n",
       "3             0.809591          0.809145         0.000778  \n",
       "4             0.736594          0.736595         0.000021  \n",
       "..                 ...               ...              ...  \n",
       "65            0.810601          0.809875         0.000861  \n",
       "66            0.903532          0.904354         0.000833  \n",
       "67            0.810601          0.809875         0.000861  \n",
       "68            0.903532          0.904354         0.000833  \n",
       "69            0.810601          0.809875         0.000861  \n",
       "\n",
       "[70 rows x 33 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(cv_result_svc)\n",
    "df.to_csv('cv_result_svc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top ranked test score for all the three classifiers\n",
    "rfc_top_rank = cv_result_rfc[cv_result_rfc['rank_test_score'] == 1].iloc[0]\n",
    "lrc_top_rank = cv_result_lrc[cv_result_lrc['rank_test_score'] == 1].iloc[0]\n",
    "svc_top_rank = cv_result_svc[cv_result_svc['rank_test_score'] == 1].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the train and test score for three classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "                       Random Forest       Logistic Regression     Support Vector   \n",
      "                       ----------------    --------------------    ---------------- \n",
      "  Mean Test Score   :  0.8184              0.8146                  0.8144\n",
      "  Mean Train Score  :  0.8385              0.8148                  0.8429\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n')\n",
    "print ('                    ',\n",
    "       '  Random Forest    ',\n",
    "       '  Logistic Regression  ',\n",
    "       '  Support Vector   ')\n",
    "print ('                    ',\n",
    "       '  ---------------- ',\n",
    "       '  -------------------- ',\n",
    "       '  ---------------- ')\n",
    "print ('  Mean Test Score   : ', \n",
    "       str('%.4f' %rfc_top_rank['mean_test_score']),\n",
    "       '            ',\n",
    "       str('%.4f' %lrc_top_rank['mean_test_score']),\n",
    "       '                ',\n",
    "       str('%.4f' %svc_top_rank['mean_test_score'])\n",
    "       )\n",
    "print ('  Mean Train Score  : ', \n",
    "       str('%.4f' %rfc_top_rank['mean_train_score']),\n",
    "       '            ',\n",
    "       str('%.4f' %lrc_top_rank['mean_train_score']),\n",
    "       '                ',\n",
    "       str('%.4f' %svc_top_rank['mean_train_score'])\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is Random Forest which gives us the better accuracy among all others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The best Parameters are : \n",
      "{'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters of the Random Forest Classifier\n",
    "print('\\n The best Parameters are : ')\n",
    "print(rfc_grid_fit.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform RandomizedSearchCV for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "data = pd.read_csv('04+-+decisiontreeAdultIncome.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dummy variables\n",
    "data_prep = pd.get_dummies(data, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and Y Variables\n",
    "X = data_prep.iloc[:, :-1]\n",
    "Y = data_prep.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and create Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters for Random Forest\n",
    "rfc_param = {'n_estimators':[10,15,20], \n",
    "            'min_samples_split':[8,16],\n",
    "            'min_samples_leaf':[1,2,3,4,5]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The parameters results in 3 x 2 x 5 = 30 different combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RandomizedSearchCV object\n",
    "rfc_rs = RandomizedSearchCV(estimator=rfc, \n",
    "                        param_distributions=rfc_param,\n",
    "                        scoring='accuracy',\n",
    "                        cv=10,\n",
    "                        n_iter=10,\n",
    "                        return_train_score=True,\n",
    "                        random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_iter selects 10 combinations out of 30 possible\n",
    "#Now 10 x 10 = 100 jobs will be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data to RandomizedSearchCV object\n",
    "rfc_rs_fit = rfc_rs.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results of RandomizedSearch\n",
    "cv_results_rfc_rs = pd.DataFrame.from_dict(rfc_rs_fit.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The best Parameters are : \n",
      "{'n_estimators': 15, 'min_samples_split': 16, 'min_samples_leaf': 5}\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters of Randomized Search for Random Forest\n",
    "print('\\n The best Parameters are : ')\n",
    "print(rfc_rs_fit.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
